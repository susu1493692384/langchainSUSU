# RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰å®Œå…¨æŒ‡å— ğŸš€

## ğŸ“š ç›®å½•

- [ä»€ä¹ˆæ˜¯RAGï¼Ÿ](#ä»€ä¹ˆæ˜¯rag)
- [RAGæ ¸å¿ƒç»„ä»¶](#ragæ ¸å¿ƒç»„ä»¶)
- [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [é«˜çº§RAGæŠ€æœ¯](#é«˜çº§ragæŠ€æœ¯)
- [å®è·µé¡¹ç›®](#å®è·µé¡¹ç›®)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [å­¦ä¹ èµ„æº](#å­¦ä¹ èµ„æº)

## ğŸ¯ ä»€ä¹ˆæ˜¯RAGï¼Ÿ

**RAG (Retrieval-Augmented Generation)** æ˜¯ä¸€ç§ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„AIæŠ€æœ¯ï¼Œå®ƒèƒ½å¤Ÿï¼š

1. **å‡å°‘å¹»è§‰**ï¼šåŸºäºçœŸå®æ–‡æ¡£å†…å®¹ç”Ÿæˆå›ç­”
2. **æé«˜å‡†ç¡®æ€§**ï¼šåˆ©ç”¨çŸ¥è¯†åº“ä¸­çš„æƒå¨ä¿¡æ¯
3. **å¢å¼ºæ—¶æ•ˆæ€§**ï¼šå¯ä»¥è½»æ¾æ›´æ–°çŸ¥è¯†åº“å†…å®¹
4. **å¯è§£é‡Šæ€§**ï¼šå¯ä»¥è¿½æº¯å›ç­”çš„ä¿¡æ¯æ¥æº

### RAGå·¥ä½œåŸç†

```mermaid
graph TD
    A[ç”¨æˆ·é—®é¢˜] --> B[é—®é¢˜ç†è§£]
    B --> C[æ–‡æ¡£æ£€ç´¢]
    C --> D[ç›¸å…³æ€§æ’åº]
    D --> E[ä¸Šä¸‹æ–‡æ„å»º]
    E --> F[LLMç”Ÿæˆå›ç­”]
    F --> G[è¿”å›ç­”æ¡ˆ]

    H[çŸ¥è¯†åº“] --> C
    I[å‘é‡å­˜å‚¨] --> D
```

## ğŸ§© RAGæ ¸å¿ƒç»„ä»¶

### 1. æ–‡æ¡£å¤„ç†å™¨ (Document Processor)
- **æ–‡æ¡£åˆ†å‰²**ï¼šå°†é•¿æ–‡æ¡£åˆ‡åˆ†ä¸ºåˆé€‚çš„å—
- **å…ƒæ•°æ®æå–**ï¼šè‡ªåŠ¨æå–æ–‡æ¡£çš„å…³é”®ä¿¡æ¯
- **é¢„å¤„ç†**ï¼šæ¸…ç†å’Œæ ‡å‡†åŒ–æ–‡æ¡£å†…å®¹

### 2. å‘é‡å­˜å‚¨ (Vector Storage)
- **åµŒå…¥æ¨¡å‹**ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º
- **å‘é‡æ•°æ®åº“**ï¼šé«˜æ•ˆå­˜å‚¨å’Œæ£€ç´¢å‘é‡
- **ç›¸ä¼¼åº¦æœç´¢**ï¼šæ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ

### 3. æ£€ç´¢å™¨ (Retriever)
- **åŸºç¡€æ£€ç´¢**ï¼šç®€å•çš„ç›¸ä¼¼åº¦æœç´¢
- **å¤šæŸ¥è¯¢æ£€ç´¢**ï¼šç”Ÿæˆå¤šä¸ªæœç´¢æŸ¥è¯¢
- **å‹ç¼©æ£€ç´¢**ï¼šç²¾ç®€æ£€ç´¢åˆ°çš„å†…å®¹
- **é‡æ’åº**ï¼šä¼˜åŒ–æ£€ç´¢ç»“æœçš„æ’åº

### 4. ç”Ÿæˆå™¨ (Generator)
- **æç¤ºå·¥ç¨‹**ï¼šè®¾è®¡æœ‰æ•ˆçš„ç”Ÿæˆæç¤º
- **ä¸Šä¸‹æ–‡ç®¡ç†**ï¼šåˆç†åˆ©ç”¨æ£€ç´¢åˆ°çš„ä¿¡æ¯
- **è¾“å‡ºæ ¼å¼åŒ–**ï¼šç”Ÿæˆç»“æ„åŒ–çš„å›ç­”

## ğŸ”§ ç¯å¢ƒå‡†å¤‡

### åŸºç¡€ä¾èµ–
```bash
# æ ¸å¿ƒLangChainåŒ…
pip install langchain langchain-openai langchain-community

# å‘é‡æ•°æ®åº“
pip install faiss-cpu chromadb

# æ–‡æ¡£å¤„ç†
pip install pypdf tiktoken

# å¯é€‰ï¼šGPUæ”¯æŒ
pip install faiss-gpu
```

### å®Œæ•´ä¾èµ–
```bash
# å®‰è£…æ‰€æœ‰RAGç›¸å…³ä¾èµ–
pip install -r requirements.txt
```

### ç¯å¢ƒå˜é‡é…ç½®
```bash
# .env æ–‡ä»¶
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key

# æœ¬åœ°æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
HUGGINGFACEHUB_API_TOKEN=your_huggingface_token
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¬¬ä¸€æ­¥ï¼šåŸºç¡€RAGç³»ç»Ÿ

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# 1. åˆå§‹åŒ–æ¨¡å‹
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.1)
embeddings = OpenAIEmbeddings()

# 2. å‡†å¤‡æ–‡æ¡£
documents = [
    "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯...",
    "æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯...",
    "æ·±åº¦å­¦ä¹ ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œ..."
]

# 3. åˆ†å‰²æ–‡æ¡£
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
chunks = text_splitter.create_documents(documents)

# 4. åˆ›å»ºå‘é‡å­˜å‚¨
vector_store = FAISS.from_documents(chunks, embeddings)

# 5. åˆ›å»ºæ£€ç´¢å™¨
retriever = vector_store.as_retriever(search_kwargs={"k": 3})

# 6. æ„å»ºRAGé“¾
template = """åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ï¼š
ä¸Šä¸‹æ–‡ï¼š{context}
é—®é¢˜ï¼š{question}
å›ç­”ï¼š"""

prompt = ChatPromptTemplate.from_template(template)

rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# 7. ä½¿ç”¨RAGç³»ç»Ÿ
question = "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"
answer = rag_chain.invoke(question)
print(answer)
```

### è¿è¡Œå®Œæ•´æ•™ç¨‹
```bash
python 04_1_rag_comprehensive.py
```

é€‰æ‹©æ¼”ç¤ºé€‰é¡¹ï¼š
- 1. åŸºç¡€RAGç³»ç»Ÿ
- 2. é«˜çº§RAGæŠ€æœ¯
- 3. å¯¹è¯å¼RAG
- 4. RAGç³»ç»Ÿè¯„ä¼°
- 5. åŸºäºæ–‡ä»¶çš„RAG

## ğŸ“ é«˜çº§RAGæŠ€æœ¯

### 1. å¤šæŸ¥è¯¢æ£€ç´¢ (Multi-Query Retrieval)

ç”Ÿæˆå¤šä¸ªä¸åŒçš„æŸ¥è¯¢æ¥æé«˜æ£€ç´¢è¦†ç›–ç‡ï¼š

```python
from langchain.retrievers.multi_query import MultiQueryRetriever

# åˆ›å»ºå¤šæŸ¥è¯¢æ£€ç´¢å™¨
multi_query_retriever = MultiQueryRetriever.from_llm(
    retriever=retriever,
    llm=llm
)

# ä½¿ç”¨å¤šæŸ¥è¯¢æ£€ç´¢
question = "æœºå™¨å­¦ä¹ æœ‰å“ªäº›ç±»å‹ï¼Ÿ"
docs = multi_query_retriever.get_relevant_documents(question)
```

**ä¼˜åŠ¿ï¼š**
- ä»ä¸åŒè§’åº¦æ£€ç´¢ä¿¡æ¯
- æé«˜å¬å›ç‡
- å‡å°‘é—æ¼ç›¸å…³ä¿¡æ¯

### 2. ä¸Šä¸‹æ–‡å‹ç¼© (Contextual Compression)

å‹ç¼©æ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼Œæå–æœ€ç›¸å…³çš„ä¿¡æ¯ï¼š

```python
from langchain.retrievers.document_compressors import LLMChainExtractor
from langchain.retrievers import ContextualCompressionRetriever

# åˆ›å»ºå‹ç¼©å™¨
compressor = LLMChainExtractor.from_llm(llm)

# åˆ›å»ºå‹ç¼©æ£€ç´¢å™¨
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor,
    base_retriever=retriever
)

# ä½¿ç”¨å‹ç¼©æ£€ç´¢
compressed_docs = compression_retriever.get_relevant_documents(question)
```

**ä¼˜åŠ¿ï¼š**
- æå–æœ€ç›¸å…³çš„ç‰‡æ®µ
- å‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦
- æé«˜ç”Ÿæˆè´¨é‡

### 3. çˆ¶å­æ–‡æ¡£æ£€ç´¢ (Parent-Child Retrieval)

ä¿æŒæ–‡æ¡£çš„å®Œæ•´æ€§åŒæ—¶æé«˜æ£€ç´¢ç²¾åº¦ï¼š

```python
from langchain.retrievers import ParentDocumentRetriever

# å­æ–‡æ¡£åˆ†å‰²å™¨ï¼ˆç”¨äºæ£€ç´¢ï¼‰
child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)

# çˆ¶æ–‡æ¡£åˆ†å‰²å™¨ï¼ˆç”¨äºç”Ÿæˆï¼‰
parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)

# åˆ›å»ºçˆ¶å­æ£€ç´¢å™¨
parent_child_retriever = ParentDocumentRetriever(
    vectorstore=vector_store,
    docstore=docstore,
    child_splitter=child_splitter,
    parent_splitter=parent_splitter
)
```

**ä¼˜åŠ¿ï¼š**
- æ—¢æœ‰ç»†ç²’åº¦çš„æ£€ç´¢ç²¾åº¦
- åˆä¿æŒæ–‡æ¡£çš„å®Œæ•´æ€§
- å¹³è¡¡æ£€ç´¢å’Œç”Ÿæˆæ•ˆæœ

### 4. è‡ªé‡æ’åºæ£€ç´¢ (Self-Query Retrieval)

æ ¹æ®æ–‡æ¡£å…ƒæ•°æ®è¿›è¡Œæ™ºèƒ½æ£€ç´¢ï¼š

```python
from langchain.chains.query_constructor.base import AttributeInfo

# å®šä¹‰æ–‡æ¡£å±æ€§
metadata_field_info = [
    AttributeInfo(
        name="source",
        description="æ–‡æ¡£æ¥æº",
        type="string",
    ),
    AttributeInfo(
        name="category",
        description="æ–‡æ¡£ç±»åˆ«",
        type="string",
    )
]

# åˆ›å»ºè‡ªæŸ¥è¯¢æ£€ç´¢å™¨
self_query_retriever = SelfQueryRetriever.from_llm(
    llm,
    vector_store,
    document_content_description="AIæŠ€æœ¯æ–‡æ¡£",
    metadata_field_info=metadata_field_info
)
```

**ä¼˜åŠ¿ï¼š**
- åŸºäºå…ƒæ•°æ®æ™ºèƒ½æ£€ç´¢
- æ”¯æŒå¤æ‚æŸ¥è¯¢æ¡ä»¶
- æé«˜æ£€ç´¢å‡†ç¡®æ€§

## ğŸ’¡ å®è·µé¡¹ç›®

### é¡¹ç›®1ï¼šæ™ºèƒ½é—®ç­”ç³»ç»Ÿ

æ„å»ºä¸€ä¸ªåŸºäºä¼ä¸šæ–‡æ¡£çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼š

```python
class EnterpriseQA:
    def __init__(self, document_paths):
        self.documents = self.load_documents(document_paths)
        self.vector_store = self.create_vector_store()
        self.rag_chain = self.create_rag_chain()

    def load_documents(self, paths):
        # åŠ è½½å„ç§æ ¼å¼çš„æ–‡æ¡£
        pass

    def create_vector_store(self):
        # åˆ›å»ºå‘é‡å­˜å‚¨
        pass

    def create_rag_chain(self):
        # åˆ›å»ºRAGé“¾
        pass

    def ask(self, question):
        # å›ç­”ç”¨æˆ·é—®é¢˜
        return self.rag_chain.invoke(question)
```

**åŠŸèƒ½ç‰¹ç‚¹ï¼š**
- æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼
- å®æ—¶æ›´æ–°çŸ¥è¯†åº“
- ç”¨æˆ·å‹å¥½çš„ç•Œé¢
- æ¥æºå¼•ç”¨å’Œå¯ä¿¡åº¦è¯„åˆ†

### é¡¹ç›®2ï¼šå­¦æœ¯è®ºæ–‡åŠ©æ‰‹

ä¸ºç ”ç©¶äººå‘˜æä¾›è®ºæ–‡æ£€ç´¢å’Œé—®ç­”æœåŠ¡ï¼š

```python
class PaperAssistant:
    def __init__(self):
        self.paper_store = PaperStore()
        self.rag_system = RAGSystem()
        self.citation_manager = CitationManager()

    def search_papers(self, query):
        # æœç´¢ç›¸å…³è®ºæ–‡
        pass

    def answer_question(self, question, papers):
        # åŸºäºè®ºæ–‡å›ç­”é—®é¢˜
        pass

    def generate_citations(self, answer):
        # ç”Ÿæˆå¼•ç”¨æ–‡çŒ®
        pass
```

**åŠŸèƒ½ç‰¹ç‚¹ï¼š**
- å­¦æœ¯è®ºæ–‡æ£€ç´¢
- æ™ºèƒ½æ–‡çŒ®ç»¼è¿°
- è‡ªåŠ¨å¼•ç”¨ç”Ÿæˆ
- ç›¸å…³æ€§æ’åº

### é¡¹ç›®3ï¼šæ³•å¾‹æ–‡æ¡£åˆ†æ

ä¸ºæ³•å¾‹å·¥ä½œè€…æä¾›æ–‡æ¡£åˆ†ææœåŠ¡ï¼š

```python
class LegalAnalyzer:
    def __init__(self):
        self.legal_knowledge_base = LegalKnowledgeBase()
        self.rag_system = RAGSystem()
        self.compliance_checker = ComplianceChecker()

    def analyze_case(self, case_text):
        # åˆ†ææ¡ˆä¾‹
        pass

    def find_relevant_laws(self, situation):
        # æŸ¥æ‰¾ç›¸å…³æ³•å¾‹
        pass

    def check_compliance(self, document):
        # æ£€æŸ¥åˆè§„æ€§
        pass
```

**åŠŸèƒ½ç‰¹ç‚¹ï¼š**
- æ³•å¾‹æ¡æ–‡æ£€ç´¢
- æ¡ˆä¾‹åˆ†æ
- åˆè§„æ€§æ£€æŸ¥
- æ³•å¾‹é£é™©è¯„ä¼°

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. æ£€ç´¢ä¼˜åŒ–

#### æ–‡æ¡£åˆ†å‰²ç­–ç•¥
```python
# é’ˆå¯¹ä¸åŒå†…å®¹çš„åˆ†å‰²ç­–ç•¥
splitter_strategies = {
    "code": RecursiveCharacterTextSplitter(
        separators=["\ndef ", "\nclass ", "\n\n", "\n"],
        chunk_size=1000,
        chunk_overlap=50
    ),
    "markdown": RecursiveCharacterTextSplitter(
        separators=["\n## ", "\n### ", "\n\n", "\n"],
        chunk_size=1500,
        chunk_overlap=100
    ),
    "general": RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
}
```

#### æ£€ç´¢å‚æ•°è°ƒä¼˜
```python
# ä¼˜åŒ–æ£€ç´¢å‚æ•°
retriever = vector_store.as_retriever(
    search_type="similarity_score_threshold",
    search_kwargs={
        "k": 5,                    # æ£€ç´¢æ–‡æ¡£æ•°é‡
        "score_threshold": 0.7,     # ç›¸å…³æ€§é˜ˆå€¼
        "fetch_k": 20              # åˆå§‹æ£€ç´¢æ•°é‡
    }
)
```

### 2. ç”Ÿæˆä¼˜åŒ–

#### æç¤ºè¯å·¥ç¨‹
```python
# ä¼˜åŒ–çš„æç¤ºæ¨¡æ¿
optimized_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

å›ç­”è¦æ±‚ï¼š
1. åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯è¿›è¡Œå›ç­”
2. å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜
3. æä¾›å…·ä½“ã€è¯¦ç»†çš„å›ç­”
4. å¼•ç”¨ä¿¡æ¯æ¥æº

ç”¨æˆ·é—®é¢˜ï¼š{question}

ä½ çš„å›ç­”ï¼š
"""
```

#### æµå¼è¾“å‡º
```python
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

# åˆ›å»ºæµå¼è¾“å‡ºçš„LLM
llm = ChatOpenAI(
    streaming=True,
    callbacks=[StreamingStdOutCallbackHandler()],
    # å…¶ä»–å‚æ•°...
)
```

### 3. ç¼“å­˜ç­–ç•¥

#### å‘é‡ç¼“å­˜
```python
# Rediså‘é‡ç¼“å­˜
import redis
from langchain.cache import RedisCache

# è®¾ç½®ç¼“å­˜
redis_cache = RedisCache(
    redis_client=redis.Redis(host='localhost', port=6379, db=0),
    ttl=3600  # 1å°æ—¶è¿‡æœŸ
)

# ä½¿ç”¨ç¼“å­˜
llm.cache = redis_cache
```

#### ç»“æœç¼“å­˜
```python
# è‡ªå®šä¹‰ç»“æœç¼“å­˜
class RAGCache:
    def __init__(self):
        self.cache = {}

    def get_cached_result(self, question):
        # è·å–ç¼“å­˜ç»“æœ
        question_hash = hashlib.md5(question.encode()).hexdigest()
        return self.cache.get(question_hash)

    def cache_result(self, question, result):
        # ç¼“å­˜ç»“æœ
        question_hash = hashlib.md5(question.encode()).hexdigest()
        self.cache[question_hash] = result
```

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•é€‰æ‹©åˆé€‚çš„æ–‡æ¡£åˆ†å‰²ç­–ç•¥ï¼Ÿ

**A:** æ ¹æ®æ–‡æ¡£ç±»å‹é€‰æ‹©ï¼š
- **æŠ€æœ¯æ–‡æ¡£**ï¼šæŒ‰ç« èŠ‚å’Œä»£ç å—åˆ†å‰²
- **å­¦æœ¯è®ºæ–‡**ï¼šæŒ‰æ®µè½å’Œç« èŠ‚åˆ†å‰²
- **æ³•å¾‹æ–‡æ¡£**ï¼šæŒ‰æ¡æ¬¾å’Œæ®µè½åˆ†å‰²
- **é€šç”¨æ–‡æœ¬**ï¼šä½¿ç”¨é€’å½’åˆ†å‰²ï¼Œè®¾ç½®åˆé€‚çš„chunk_size(800-1500)

### Q2: æ£€ç´¢ç»“æœä¸ç›¸å…³æ€ä¹ˆåŠï¼Ÿ

**A:** ä¼˜åŒ–æ£€ç´¢ç­–ç•¥ï¼š
1. å¢åŠ æ£€ç´¢æ•°é‡ (kå€¼)
2. è°ƒæ•´åˆ†å‰²ç­–ç•¥
3. ä½¿ç”¨å¤šæŸ¥è¯¢æ£€ç´¢
4. ä¼˜åŒ–åµŒå…¥æ¨¡å‹
5. æ·»åŠ é‡æ’åºæ­¥éª¤

### Q3: å¦‚ä½•å¤„ç†é•¿æ–‡æ¡£ï¼Ÿ

**A:** é•¿æ–‡æ¡£å¤„ç†ç­–ç•¥ï¼š
1. **çˆ¶å­æ£€ç´¢**ï¼šä¿æŒæ–‡æ¡£å®Œæ•´æ€§
2. **å±‚æ¬¡åŒ–ç´¢å¼•**ï¼šåˆ›å»ºå¤šçº§ç´¢å¼•
3. **æ‘˜è¦å…ˆè¡Œ**ï¼šå…ˆç”Ÿæˆæ‘˜è¦å†è¯¦ç»†æ£€ç´¢
4. **åˆ†å—ç­–ç•¥**ï¼šæ™ºèƒ½åˆ†å‰²æ–‡æ¡£

### Q4: å¦‚ä½•å‡å°‘å¹»è§‰ï¼Ÿ

**A:** å‡å°‘å¹»è§‰çš„æ–¹æ³•ï¼š
1. **ä¸¥æ ¼æ£€ç´¢**ï¼šåªåŸºäºæ£€ç´¢åˆ°çš„å†…å®¹å›ç­”
2. **æ¥æºå¼•ç”¨**ï¼šæ˜ç¡®æ ‡æ³¨ä¿¡æ¯æ¥æº
3. **ç½®ä¿¡åº¦è¯„åˆ†**ï¼šè¯„ä¼°å›ç­”çš„å¯ä¿¡åº¦
4. **å¤šæºéªŒè¯**ï¼šäº¤å‰éªŒè¯å¤šä¸ªæ¥æº

### Q5: å¦‚ä½•è¯„ä¼°RAGç³»ç»Ÿæ€§èƒ½ï¼Ÿ

**A:** è¯„ä¼°æŒ‡æ ‡ï¼š
1. **æ£€ç´¢è´¨é‡**ï¼šå¬å›ç‡ã€ç²¾ç¡®ç‡ã€F1åˆ†æ•°
2. **å›ç­”è´¨é‡**ï¼šå‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€æµç•…æ€§
3. **ç”¨æˆ·ä½“éªŒ**ï¼šå“åº”æ—¶é—´ã€ç”¨æˆ·æ»¡æ„åº¦
4. **ç³»ç»Ÿæ€§èƒ½**ï¼šååé‡ã€èµ„æºä½¿ç”¨ç‡

## ğŸ“Š æ€§èƒ½ç›‘æ§

### æ£€ç´¢æ€§èƒ½ç›‘æ§
```python
class RetrievalMonitor:
    def __init__(self):
        self.metrics = {
            "total_queries": 0,
            "total_retrieval_time": 0,
            "avg_retrieved_docs": 0,
            "avg_relevance_score": 0
        }

    def track_retrieval(self, query, docs, retrieval_time):
        # è·Ÿè¸ªæ£€ç´¢æ€§èƒ½
        self.metrics["total_queries"] += 1
        self.metrics["total_retrieval_time"] += retrieval_time
        self.metrics["avg_retrieved_docs"] = (
            (self.metrics["avg_retrieved_docs"] * (self.metrics["total_queries"] - 1) + len(docs)) /
            self.metrics["total_queries"]
        )

    def get_stats(self):
        return self.metrics
```

### ç”Ÿæˆæ€§èƒ½ç›‘æ§
```python
class GenerationMonitor:
    def __init__(self):
        self.metrics = {
            "total_generations": 0,
            "total_generation_time": 0,
            "total_tokens": 0,
            "avg_response_length": 0
        }

    def track_generation(self, response, generation_time):
        # è·Ÿè¸ªç”Ÿæˆæ€§èƒ½
        self.metrics["total_generations"] += 1
        self.metrics["total_generation_time"] += generation_time
        self.metrics["total_tokens"] += len(response.split())
        self.metrics["avg_response_length"] = (
            (self.metrics["avg_response_length"] * (self.metrics["total_generations"] - 1) + len(response)) /
            self.metrics["total_generations"]
        )
```

## ğŸŒŸ é«˜çº§ç‰¹æ€§

### 1. å¤šæ¨¡æ€RAG

æ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç­‰å¤šç§æ¨¡æ€ï¼š

```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from PIL import Image

# å¤šæ¨¡æ€åµŒå…¥
class MultiModalEmbeddings:
    def __init__(self):
        self.text_embeddings = OpenAIEmbeddings()
        self.image_embeddings = ImageEmbeddings()

    def embed_text(self, text):
        return self.text_embeddings.embed_query(text)

    def embed_image(self, image_path):
        return self.image_embeddings.embed_image(image_path)
```

### 2. çŸ¥è¯†å›¾è°±å¢å¼º

ç»“åˆçŸ¥è¯†å›¾è°±æå‡RAGæ•ˆæœï¼š

```python
from langchain.graphs import Neo4jGraph

# çŸ¥è¯†å›¾è°±RAG
class KnowledgeGraphRAG:
    def __init__(self):
        self.graph = Neo4jGraph()
        self.rag_system = RAGSystem()

    def enhance_context(self, query, docs):
        # ç”¨çŸ¥è¯†å›¾è°±å¢å¼ºä¸Šä¸‹æ–‡
        entities = self.extract_entities(query)
        graph_info = self.query_graph(entities)
        return self.combine_context(docs, graph_info)
```

### 3. å®æ—¶æ›´æ–°RAG

æ”¯æŒçŸ¥è¯†åº“çš„å®æ—¶æ›´æ–°ï¼š

```python
class RealTimeRAG:
    def __init__(self):
        self.vector_store = Chroma()
        self.update_queue = []

    def add_documents(self, documents):
        # æ·»åŠ æ–°æ–‡æ¡£
        self.vector_store.add_documents(documents)

    def update_document(self, doc_id, new_content):
        # æ›´æ–°æ–‡æ¡£
        self.vector_store.update_document(doc_id, new_content)

    def delete_document(self, doc_id):
        # åˆ é™¤æ–‡æ¡£
        self.vector_store.delete_document(doc_id)
```

## ğŸ› ï¸ éƒ¨ç½²æŒ‡å—

### 1. Dockeréƒ¨ç½²

```dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 2. Kuberneteséƒ¨ç½²

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rag-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: rag-service
  template:
    metadata:
      labels:
        app: rag-service
    spec:
      containers:
      - name: rag-service
        image: rag-service:latest
        ports:
        - containerPort: 8000
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: api-keys
              key: openai-key
```

### 3. ç›‘æ§å’Œæ—¥å¿—

```python
# Prometheusç›‘æ§
from prometheus_client import Counter, Histogram, start_http_server

REQUEST_COUNT = Counter('rag_requests_total', 'Total RAG requests')
REQUEST_LATENCY = Histogram('rag_request_duration_seconds', 'RAG request latency')

# è®°å½•æŒ‡æ ‡
@REQUEST_LATENCY.time()
def process_rag_request(request):
    REQUEST_COUNT.inc()
    # å¤„ç†è¯·æ±‚
    return response
```

## ğŸ“š å­¦ä¹ èµ„æº

### å®˜æ–¹æ–‡æ¡£
- [LangChain RAGæ–‡æ¡£](https://python.langchain.com/docs/use_cases/question_answering/)
- [FAISSæ–‡æ¡£](https://faiss.ai/)
- [Chromaæ–‡æ¡£](https://docs.trychroma.com/)

### ç ”ç©¶è®ºæ–‡
- [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)
- [Dense Passage Retrieval for Open-Domain Question Answering](https://arxiv.org/abs/2004.04906)

### å®æˆ˜æ•™ç¨‹
- [RAGç³»ç»Ÿæ„å»ºæ•™ç¨‹](https://github.com/langchain-ai/langchain/tree/master/docs/extras/use_cases/question_answering)
- [å‘é‡æ•°æ®åº“æ¯”è¾ƒ](https://zilliz.com/comparison)

### ç¤¾åŒºèµ„æº
- [LangChain Discord](https://discord.gg/langchain)
- [RAGæœ€ä½³å®è·µ](https://github.com/run-llama/llama_index)

---

## ğŸ‰ æ€»ç»“

RAGæŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼ŒæŒæ¡è¿™é¡¹æŠ€æœ¯å°†ä¸ºæ‚¨æ‰“å¼€AIåº”ç”¨å¼€å‘çš„æ–°ä¸–ç•Œã€‚é€šè¿‡æœ¬æŒ‡å—çš„å­¦ä¹ ï¼Œæ‚¨å·²ç»å…·å¤‡äº†ï¼š

âœ… **ç†è®ºåŸºç¡€**ï¼šç†è§£RAGçš„æ ¸å¿ƒæ¦‚å¿µå’Œå·¥ä½œåŸç†
âœ… **å®è·µèƒ½åŠ›**ï¼šèƒ½å¤Ÿæ„å»ºå®Œæ•´çš„RAGç³»ç»Ÿ
âœ… **ä¼˜åŒ–æŠ€å·§**ï¼šæŒæ¡æ€§èƒ½ä¼˜åŒ–å’Œè°ƒä¼˜æ–¹æ³•
âœ… **é¡¹ç›®ç»éªŒ**ï¼šäº†è§£å®é™…åº”ç”¨åœºæ™¯å’Œæœ€ä½³å®è·µ

### ä¸‹ä¸€æ­¥å»ºè®®

1. **æ·±å…¥å®è·µ**ï¼šæ„å»ºè‡ªå·±çš„RAGåº”ç”¨
2. **æ¢ç´¢å‰æ²¿**ï¼šå…³æ³¨æœ€æ–°çš„RAGç ”ç©¶è¿›å±•
3. **ç¤¾åŒºå‚ä¸**ï¼šåˆ†äº«æ‚¨çš„ç»éªŒå’Œè§è§£
4. **æŒç»­å­¦ä¹ **ï¼šè·Ÿä¸ŠAIæŠ€æœ¯çš„å¿«é€Ÿå‘å±•

ç¥æ‚¨åœ¨RAGæŠ€æœ¯çš„å­¦ä¹ å’Œåº”ç”¨ä¸­å–å¾—æˆåŠŸï¼ğŸš€