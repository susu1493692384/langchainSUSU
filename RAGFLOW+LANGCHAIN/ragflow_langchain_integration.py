#!/usr/bin/env python3
"""
RAGFlow + LangChain é›†æˆç¤ºä¾‹
å±•ç¤ºå¦‚ä½•åœ¨LangChainä¸­ä½¿ç”¨RAGFlowçš„çŸ¥è¯†åº“
"""

import os
import json
import requests
from typing import List, Dict, Any, Optional
import numpy as np
from datetime import datetime
from dotenv import load_dotenv

from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever
from langchain_core.embeddings import Embeddings
from pydantic import BaseModel, Field, ConfigDict
from langchain_community.vectorstores import FAISS, Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_openai.chat_models.base import ChatOpenAI as OpenAIChatBase
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def create_embeddings() -> Embeddings:
    """åˆ›å»º embeddings å®ä¾‹ï¼Œæ”¯æŒå¤šç§é…ç½®"""
    if os.getenv("GLM_API_KEY"):
        # ä½¿ç”¨ GLM çš„ embeddings (å…¼å®¹ OpenAI æ ¼å¼çš„ API)
        try:
            return OpenAIEmbeddings(
                model=os.getenv("EMBEDDING_MODEL", "embedding-2"),
                openai_api_key=os.getenv("GLM_API_KEY"),
                openai_api_base=os.getenv("GLM_BASE_URL", "https://open.bigmodel.cn/api/paas/v4/")
            )
        except Exception as e:
            print(f"GLM embeddings åˆå§‹åŒ–å¤±è´¥: {e}")
            print("å›é€€åˆ° OpenAI embeddings")

    # é»˜è®¤ä½¿ç”¨ OpenAI embeddings
    return OpenAIEmbeddings(
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )

# ========================
# RAGFlow API è¿æ¥å™¨
# ========================

class RAGFlowAPIConnector:
    """RAGFlow APIè¿æ¥å™¨ - é€šè¿‡APIè®¿é—®RAGFlowçŸ¥è¯†åº“"""

    def __init__(self,
                 base_url: str = None,
                 api_key: str = None,
                 timeout: int = 60):
        """
        åˆå§‹åŒ–RAGFlow APIè¿æ¥å™¨

        Args:
            base_url: RAGFlow APIæœåŠ¡åœ°å€ (é»˜è®¤ä»ç¯å¢ƒå˜é‡ RAGFLOW_API_URL è·å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ http://localhost:9380)
                       æ³¨æ„ï¼šä¸æ˜¯ Web UI ç«¯å£(9000)ï¼Œè€Œæ˜¯ API æœåŠ¡ç«¯å£(9380)
            api_key: APIå¯†é’¥ (ä»ç¯å¢ƒå˜é‡ RAGFLOW_API_KEY è·å–)
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´
        """
        self.base_url = (os.getenv("RAGFLOW_API_URL") if base_url is None else base_url).rstrip('/')
        self.api_key = api_key or os.getenv("RAGFLOW_API_KEY")
        self.timeout = timeout
        self.session = requests.Session()

        # è®¾ç½®è¯·æ±‚å¤´
        self.session.headers.update({
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {self.api_key}' if self.api_key else None
        })

    def test_connection(self) -> bool:
        """æµ‹è¯•RAGFlowè¿æ¥"""
        try:
            # å°è¯•å¤šä¸ªå¯èƒ½çš„å¥åº·æ£€æŸ¥ç«¯ç‚¹
            endpoints = ["/api/health", "/health", "/", "/api/v1/datasets"]

            for endpoint in endpoints:
                try:
                    response = self.session.get(f"{self.base_url}{endpoint}", timeout=10)
                    if response.status_code in [200, 401, 403]:  # 200æˆåŠŸï¼Œ401/403è¯´æ˜æœåŠ¡å¯ç”¨ä½†éœ€è¦è®¤è¯
                        return True
                except:
                    continue

            print("æ‰€æœ‰å¥åº·æ£€æŸ¥ç«¯ç‚¹éƒ½æ— æ³•è®¿é—®")
            return False
        except Exception as e:
            print(f"è¿æ¥RAGFlowå¤±è´¥: {e}")
            return False

    def get_knowledge_bases(self) -> List[Dict]:
        """è·å–æ‰€æœ‰çŸ¥è¯†åº“åˆ—è¡¨"""
        try:
            # ä½¿ç”¨æ­£ç¡®çš„ RAGFlow API ç«¯ç‚¹
            response = self.session.get(f"{self.base_url}/api/v1/datasets", timeout=self.timeout)
            if response.status_code == 200:
                result = response.json()

                # RAGFlow API è¿”å›æ ¼å¼: {"code": 0, "data": [...], "message": "success"}
                if result.get("code") == 0 and isinstance(result.get("data"), list):
                    return result.get("data", [])
                else:
                    # API è¿”å›é”™è¯¯
                    print(f"API é”™è¯¯: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                    return []
            else:
                print(f"è·å–çŸ¥è¯†åº“å¤±è´¥: HTTP {response.status_code}")
                return []
        except Exception as e:
            print(f"è·å–çŸ¥è¯†åº“å¼‚å¸¸: {e}")
            return []

    def search_knowledge_base(self,
                            kb_name: str,
                            query: str,
                            top_k: int = 5,
                            similarity_threshold: float = 0.7) -> List[Dict]:
        """
        åœ¨æŒ‡å®šçŸ¥è¯†åº“ä¸­æœç´¢

        Args:
            kb_name: çŸ¥è¯†åº“åç§°
            query: æŸ¥è¯¢å†…å®¹
            top_k: è¿”å›ç»“æœæ•°é‡
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            # RAGFlow æœç´¢ API å‚æ•°æ ¼å¼
            data = {
                "question": query,
                "dataset_ids": [kb_name],  # RAGFlow ä½¿ç”¨ dataset_ids æ•°ç»„
                "top_k": top_k,
                "similarity_threshold": similarity_threshold
            }

            # ä½¿ç”¨ RAGFlow çš„æœç´¢ç«¯ç‚¹
            response = self.session.post(
                f"{self.base_url}/api/v1/retrieval",
                json=data,
                timeout=self.timeout
            )

            if response.status_code == 200:
                result = response.json()

                # RAGFlow API è¿”å›æ ¼å¼æ£€æŸ¥
                if result.get("code") == 0:
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
                    data = result.get("data", {})
                    if isinstance(data, dict):
                        # æ£€æŸ¥ä¸åŒçš„å¯èƒ½çš„æ•°æ®ç»“æ„
                        chunks = data.get("chunks", [])
                        if not chunks:
                            # å¦‚æœæ²¡æœ‰ chunksï¼Œå¯èƒ½æ•°æ®åœ¨ "data" ä¸‹é¢
                            if isinstance(data, list):
                                chunks = data
                            else:
                                # å°è¯•å…¶ä»–å­—æ®µ
                                chunks = data.get("documents", data.get("results", []))

                        if isinstance(chunks, list) and chunks:
                            # è½¬æ¢ä¸ºç»Ÿä¸€çš„æ ¼å¼
                            formatted_results = []
                            for chunk in chunks:
                                # å¤„ç†ä¸åŒçš„æ•°æ®ç»“æ„
                                if isinstance(chunk, dict):
                                    content = chunk.get("content", chunk.get("text", str(chunk)))
                                    score = chunk.get("similarity", chunk.get("score", 0.0))
                                    doc_id = chunk.get("document_id", chunk.get("id", ""))
                                    title = chunk.get("document_name", chunk.get("title", chunk.get("document_keyword", "")))
                                    source = chunk.get("document_source", chunk.get("source", "ragflow"))

                                    formatted_results.append({
                                        "content": content,
                                        "source": source,
                                        "score": score,
                                        "doc_id": doc_id,
                                        "title": title,
                                        "url": chunk.get("document_source", ""),
                                        "raw_data": chunk
                                    })
                                else:
                                    # å¦‚æœ chunk ä¸æ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                                    formatted_results.append({
                                        "content": str(chunk),
                                        "source": "ragflow",
                                        "score": 0.0,
                                        "doc_id": "",
                                        "title": "",
                                        "url": "",
                                        "raw_data": chunk
                                    })
                            return formatted_results

                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ° chunksï¼Œè¿”å›ç©ºåˆ—è¡¨
                    return []
                else:
                    print(f"æœç´¢ API é”™è¯¯: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                    return []
            else:
                print(f"æœç´¢å¤±è´¥: HTTP {response.status_code}")
                return []

        except Exception as e:
            print(f"æœç´¢å¼‚å¸¸: {e}")
            return []

    def get_document_content(self, doc_id: str) -> str:
        """è·å–æ–‡æ¡£å†…å®¹"""
        try:
            response = self.session.get(
                f"{self.base_url}/api/documents/{doc_id}",
                timeout=self.timeout
            )

            if response.status_code == 200:
                return response.json().get("content", "")
            else:
                print(f"è·å–æ–‡æ¡£å†…å®¹å¤±è´¥: {response.status_code}")
                return ""

        except Exception as e:
            print(f"è·å–æ–‡æ¡£å†…å®¹å¼‚å¸¸: {e}")
            return ""

# ========================
# RAGFlow æ£€ç´¢å™¨
# ========================

class RAGFlowRetriever(BaseRetriever):
    """RAGFlowæ£€ç´¢å™¨ - å°†RAGFlowé›†æˆåˆ°LangChainä¸­"""

    connector: RAGFlowAPIConnector = Field(description="RAGFlowè¿æ¥å™¨")
    kb_name: str = Field(description="çŸ¥è¯†åº“åç§°")
    top_k: int = Field(default=5, description="è¿”å›ç»“æœæ•°é‡")
    similarity_threshold: float = Field(default=0.7, description="ç›¸ä¼¼åº¦é˜ˆå€¼")

    model_config = ConfigDict(arbitrary_types_allowed=True)

    def _get_relevant_documents(self, query: str) -> List[Document]:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        # è°ƒç”¨RAGFlow APIæœç´¢
        search_results = self.connector.search_knowledge_base(
            kb_name=self.kb_name,  # ä½¿ç”¨çŸ¥è¯†åº“IDæˆ–åç§°
            query=query,
            top_k=self.top_k,
            similarity_threshold=self.similarity_threshold
        )

        # è½¬æ¢ä¸ºLangChain Documentæ ¼å¼
        documents = []
        for result in search_results:
            doc = Document(
                page_content=result.get("content", ""),
                metadata={
                    "source": result.get("source", "ragflow"),
                    "score": result.get("score", 0.0),
                    "doc_id": result.get("doc_id", ""),
                    "kb_name": self.kb_name,
                    "title": result.get("title", ""),
                    "url": result.get("url", "")
                }
            )
            documents.append(doc)

        return documents

    def get_relevant_documents(self, query: str) -> List[Document]:
        """å…¬å…±æ–¹æ³•ï¼šæ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        return self._get_relevant_documents(query)

# ========================
# å¤šçŸ¥è¯†åº“æ£€ç´¢å™¨
# ========================

class MultiKBRetriever(BaseRetriever):
    """å¤šçŸ¥è¯†åº“æ£€ç´¢å™¨ - èƒ½å¤ŸåŒæ—¶æœç´¢å¤šä¸ªçŸ¥è¯†åº“"""

    retrievers: Dict[str, Any] = Field(default_factory=dict, description="çŸ¥è¯†åº“æ£€ç´¢å™¨å­—å…¸")
    app: Any = Field(description="RAGFlowåº”ç”¨å®ä¾‹")

    def __init__(self, app, kb_names):
        super().__init__(
            app=app,
            retrievers={}
        )
        for kb_name in kb_names:
            self.retrievers[kb_name] = app.create_retriever(kb_name)

    def _get_relevant_documents(self, query: str) -> List[Document]:
        """ä»æ‰€æœ‰çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        all_docs = []
        for kb_name, retriever in self.retrievers.items():
            docs = retriever.get_relevant_documents(query)
            # æ·»åŠ çŸ¥è¯†åº“æ ‡è¯†
            for doc in docs:
                doc.metadata["knowledge_base"] = kb_name
            all_docs.extend(docs)

        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        all_docs.sort(key=lambda x: x.metadata.get("score", 0), reverse=True)
        return all_docs[:10]  # è¿”å›å‰10ä¸ªç»“æœ

    def get_relevant_documents(self, query: str) -> List[Document]:
        """å…¬å…±æ–¹æ³•ï¼šæ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        return self._get_relevant_documents(query)

    model_config = ConfigDict(arbitrary_types_allowed=True)

# ========================
# RAGFlow æ•°æ®å¯¼å‡ºå¯¼å…¥å·¥å…·
# ========================

class RAGFlowDataMigrator:
    """RAGFlowæ•°æ®è¿ç§»å·¥å…· - ä»RAGFlowå¯¼å‡ºæ•°æ®åˆ°LangChain"""

    def __init__(self, connector: RAGFlowAPIConnector):
        self.connector = connector

    def export_knowledge_base(self, kb_name: str, output_file: str) -> bool:
        """å¯¼å‡ºçŸ¥è¯†åº“æ•°æ®"""
        try:
            # è·å–çŸ¥è¯†åº“ä¸­çš„æ‰€æœ‰æ–‡æ¡£ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…å¯èƒ½éœ€è¦åˆ†é¡µï¼‰
            # è¿™é‡Œå‡è®¾RAGFlowæœ‰å¯¼å‡ºAPI
            export_data = {
                "kb_name": kb_name,
                "documents": [],
                "metadata": {
                    "export_time": str(datetime.now()),
                    "source": "ragflow"
                }
            }

            # å®é™…å®ç°éœ€è¦è°ƒç”¨RAGFlowçš„å¯¼å‡ºAPI
            # response = self.connector.export_kb(kb_name)
            # export_data["documents"] = response.json()

            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)

            print(f"çŸ¥è¯†åº“ '{kb_name}' å·²å¯¼å‡ºåˆ° {output_file}")
            return True

        except Exception as e:
            print(f"å¯¼å‡ºçŸ¥è¯†åº“å¤±è´¥: {e}")
            return False

    def import_to_langchain_vectorstore(self,
                                       export_file: str,
                                       embeddings: Embeddings,
                                       vectorstore_type: str = "faiss") -> Any:
        """å¯¼å…¥åˆ°LangChainå‘é‡å­˜å‚¨"""
        try:
            # åŠ è½½å¯¼å‡ºçš„æ•°æ®
            with open(export_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # è½¬æ¢ä¸ºLangChain Documentæ ¼å¼
            documents = []
            for doc_data in data["documents"]:
                doc = Document(
                    page_content=doc_data.get("content", ""),
                    metadata={
                        "source": doc_data.get("source", "ragflow"),
                        "kb_name": data["kb_name"],
                        "doc_id": doc_data.get("doc_id", ""),
                        "title": doc_data.get("title", ""),
                        **doc_data.get("metadata", {})
                    }
                )
                documents.append(doc)

            # åˆ›å»ºå‘é‡å­˜å‚¨
            if vectorstore_type.lower() == "faiss":
                vectorstore = FAISS.from_documents(documents, embeddings)
            elif vectorstore_type.lower() == "chroma":
                vectorstore = Chroma.from_documents(documents, embeddings)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å‘é‡å­˜å‚¨ç±»å‹: {vectorstore_type}")

            print(f"æˆåŠŸå¯¼å…¥ {len(documents)} ä¸ªæ–‡æ¡£åˆ° {vectorstore_type}")
            return vectorstore

        except Exception as e:
            print(f"å¯¼å…¥åˆ°LangChainå¤±è´¥: {e}")
            return None

# ========================
# RAGFlow + LangChain åº”ç”¨ç¤ºä¾‹
# ========================

class RAGFlowLangChainApp:
    """RAGFlow + LangChain åº”ç”¨ç±»"""

    def __init__(self,
                 ragflow_url: str = None,
                 ragflow_api_key: str = None,
                 llm_model: str = "glm-4.5"):
        """
        åˆå§‹åŒ–åº”ç”¨

        Args:
            ragflow_url: RAGFlow APIæœåŠ¡åœ°å€ (é»˜è®¤ä»ç¯å¢ƒå˜é‡è·å–)
            ragflow_api_key: RAGFlow APIå¯†é’¥ (é»˜è®¤ä»ç¯å¢ƒå˜é‡è·å–)
            llm_model: ä½¿ç”¨çš„LLMæ¨¡å‹
        """
        # åˆå§‹åŒ–RAGFlowè¿æ¥å™¨
        self.connector = RAGFlowAPIConnector(
            base_url=ragflow_url,
            api_key=ragflow_api_key
        )

        # åˆå§‹åŒ–LLM - æ”¯æŒ GLM æˆ– OpenAI
        if os.getenv("GLM_API_KEY"):
            # ä½¿ç”¨ GLM (å…¼å®¹ OpenAI æ ¼å¼çš„ API)
            self.llm = ChatOpenAI(
                model=os.getenv("LLM_MODEL", "GLM-4.5"),
                temperature=0.1,
                openai_api_key=os.getenv("GLM_API_KEY"),
                openai_api_base=os.getenv("GLM_BASE_URL", "https://open.bigmodel.cn/api/coding/paas/v4")
            )
        else:
            # ä½¿ç”¨ OpenAI (é»˜è®¤)
            self.llm = ChatOpenAI(
                model=llm_model,
                temperature=0.1,
                openai_api_key=os.getenv("OPENAI_API_KEY")
            )

        # å¯ç”¨çš„çŸ¥è¯†åº“
        self.available_kbs = []

        # åˆ›å»ºçš„æ£€ç´¢å™¨ç¼“å­˜
        self.retrievers = {}

    def initialize(self) -> bool:
        """åˆå§‹åŒ–åº”ç”¨"""
        print("æ­£åœ¨åˆå§‹åŒ–RAGFlow + LangChainåº”ç”¨...")

        # æµ‹è¯•RAGFlowè¿æ¥
        if not self.connector.test_connection():
            print("âŒ RAGFlowè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ")
            return False

        # è·å–å¯ç”¨çŸ¥è¯†åº“
        self.available_kbs = self.connector.get_knowledge_bases()
        print(f"âœ… è¿æ¥æˆåŠŸï¼Œå‘ç° {len(self.available_kbs)} ä¸ªçŸ¥è¯†åº“")

        for kb in self.available_kbs:
            if isinstance(kb, str):
                print(f"  - {kb}")
            elif isinstance(kb, dict):
                print(f"  - {kb.get('name', 'æœªçŸ¥')}: {kb.get('description', 'æ— æè¿°')}")
            else:
                print(f"  - {str(kb)}")

        return True

    def create_retriever(self, kb_name: str, top_k: int = 5) -> Optional[RAGFlowRetriever]:
        """åˆ›å»ºRAGFlowæ£€ç´¢å™¨"""
        # å¤„ç†çŸ¥è¯†åº“åç§°æ¯”è¾ƒï¼Œæ”¯æŒå­—ç¬¦ä¸²å’Œå­—å…¸æ ¼å¼
        available_kb_identifiers = []
        for kb in self.available_kbs:
            if isinstance(kb, str):
                available_kb_identifiers.append(kb)
            elif isinstance(kb, dict):
                # åŒæ—¶æ”¯æŒ ID å’Œ åç§°
                available_kb_identifiers.append(kb.get('id'))
                available_kb_identifiers.append(kb.get('name'))

        if kb_name not in available_kb_identifiers:
            print(f"çŸ¥è¯†åº“ '{kb_name}' ä¸å­˜åœ¨")
            print(f"å¯ç”¨çŸ¥è¯†åº“æ ‡è¯†ç¬¦: {[x for x in available_kb_identifiers if x]}")
            return None

        retriever = RAGFlowRetriever(
            connector=self.connector,
            kb_name=kb_name,
            top_k=top_k,
            similarity_threshold=0.1
        )

        self.retrievers[kb_name] = retriever
        print(f"âœ… ä¸ºçŸ¥è¯†åº“ '{kb_name}' åˆ›å»ºæ£€ç´¢å™¨æˆåŠŸ")

        return retriever

    def create_multi_kb_retriever(self, kb_names: List[str] = None):
        """åˆ›å»ºå¤šçŸ¥è¯†åº“æ£€ç´¢å™¨"""
        if kb_names is None:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šçŸ¥è¯†åº“åç§°ï¼Œä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„çŸ¥è¯†åº“
            kb_names = []
            for kb in self.available_kbs:
                if isinstance(kb, str):
                    kb_names.append(kb)
                elif isinstance(kb, dict):
                    kb_names.append(kb.get('id'))

        return MultiKBRetriever(self, kb_names)

    def create_multi_kb_qa_chain(self, multi_retriever: MultiKBRetriever, chain_type: str = "with_sources") -> Any:
        """åˆ›å»ºå¤šçŸ¥è¯†åº“QAé“¾"""
        if chain_type == "basic":
            return self._create_basic_multi_kb_qa_chain(multi_retriever)
        elif chain_type == "contextual":
            return self._create_contextual_multi_kb_qa_chain(multi_retriever)
        elif chain_type == "with_sources":
            return self._create_multi_kb_qa_chain_with_sources(multi_retriever)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„é“¾ç±»å‹: {chain_type}")

    def _create_basic_multi_kb_qa_chain(self, multi_retriever: MultiKBRetriever):
        """åˆ›å»ºåŸºç¡€å¤šçŸ¥è¯†åº“QAé“¾"""
        template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®åœ°è¯´æ˜ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·æä¾›è¯¦ç»†ã€å‡†ç¡®çš„å›ç­”ï¼š"""

        prompt = PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )

        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)

        chain = (
            {
                "context": multi_retriever | format_docs,
                "question": RunnablePassthrough()
            }
            | prompt
            | self.llm
            | StrOutputParser()
        )

        return chain

    def _create_multi_kb_qa_chain_with_sources(self, multi_retriever: MultiKBRetriever):
        """åˆ›å»ºå¸¦æ¥æºçš„å¤šçŸ¥è¯†åº“QAé“¾"""
        template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œå¹¶åœ¨å›ç­”ä¸­å¼•ç”¨ä¿¡æ¯æ¥æºã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·æä¾›è¯¦ç»†ã€å‡†ç¡®çš„å›ç­”ï¼Œå¹¶æ ‡æ³¨ä¿¡æ¯æ¥æºï¼š"""

        prompt = PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )

        def format_docs_with_sources(docs):
            """æ ¼å¼åŒ–æ–‡æ¡£ï¼ŒåŒ…å«æ¥æºä¿¡æ¯"""
            formatted_docs = []
            for i, doc in enumerate(docs, 1):
                source = doc.metadata.get("source", "æœªçŸ¥")
                title = doc.metadata.get("title", "")
                kb_name = doc.metadata.get("knowledge_base", "æœªçŸ¥")
                score = doc.metadata.get("score", 0.0)

                doc_content = f"æ–‡æ¡£ {i} (çŸ¥è¯†åº“: {kb_name}, æ¥æº: {source}, ç›¸ä¼¼åº¦: {score:.3f})\n"
                if title:
                    doc_content += f"æ ‡é¢˜: {title}\n"
                doc_content += f"å†…å®¹: {doc.page_content}"

                formatted_docs.append(doc_content)

            return "\n\n---\n\n".join(formatted_docs)

        chain = (
            {
                "context": multi_retriever | format_docs_with_sources,
                "question": RunnablePassthrough()
            }
            | prompt
            | self.llm
            | StrOutputParser()
        )

        return chain

    def create_qa_chain(self, kb_name: str, chain_type: str = "with_sources") -> Any:
        """åˆ›å»ºQAé“¾"""
        retriever = self.retrievers.get(kb_name)
        if not retriever:
            retriever = self.create_retriever(kb_name)
            if not retriever:
                return None

        if chain_type == "basic":
            return self._create_basic_qa_chain(retriever)
        elif chain_type == "contextual":
            return self._create_contextual_qa_chain(retriever)
        elif chain_type == "with_sources":
            return self._create_qa_chain_with_sources(retriever)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„é“¾ç±»å‹: {chain_type}")

    def _create_basic_qa_chain(self, retriever: RAGFlowRetriever):
        """åˆ›å»ºåŸºç¡€QAé“¾"""
        template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®åœ°è¯´æ˜ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·æä¾›è¯¦ç»†ã€å‡†ç¡®çš„å›ç­”ï¼š"""

        prompt = PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )

        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)

        chain = (
            {
                "context": retriever | format_docs,
                "question": RunnablePassthrough()
            }
            | prompt
            | self.llm
            | StrOutputParser()
        )

        return chain

    def _create_contextual_qa_chain(self, retriever: RAGFlowRetriever):
        """åˆ›å»ºä¸Šä¸‹æ–‡å¢å¼ºQAé“¾"""
        template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·åŸºäºçŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜ã€‚

çŸ¥è¯†åº“ä¸Šä¸‹æ–‡ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­ä¿¡æ¯ä¸è¶³ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚
å›ç­”æ—¶è¯·ä¿æŒä¸“ä¸šæ€§å’Œå‹å¥½æ€§ï¼š"""

        prompt = ChatPromptTemplate.from_template(template)

        def format_docs_with_scores(docs):
            """æ ¼å¼åŒ–æ–‡æ¡£ï¼ŒåŒ…å«ç›¸ä¼¼åº¦åˆ†æ•°"""
            formatted_docs = []
            for doc in docs:
                score = doc.metadata.get("score", 0.0)
                source = doc.metadata.get("source", "æœªçŸ¥")
                formatted_docs.append(f"[ç›¸ä¼¼åº¦: {score:.3f}] æ¥æº: {source}\n{doc.page_content}")
            return "\n\n---\n\n".join(formatted_docs)

        chain = (
            {
                "context": retriever | format_docs_with_scores,
                "question": RunnablePassthrough()
            }
            | prompt
            | self.llm
            | StrOutputParser()
        )

        return chain

    def _create_qa_chain_with_sources(self, retriever: RAGFlowRetriever):
        """åˆ›å»ºå¸¦æ¥æºå¼•ç”¨çš„QAé“¾"""
        template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œå¹¶åœ¨å›ç­”ä¸­å¼•ç”¨ä¿¡æ¯æ¥æºã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·æä¾›è¯¦ç»†ã€å‡†ç¡®çš„å›ç­”ï¼Œå¹¶æ ‡æ³¨ä¿¡æ¯æ¥æºï¼š"""

        prompt = PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )

        def format_docs_with_sources(docs):
            """æ ¼å¼åŒ–æ–‡æ¡£ï¼ŒåŒ…å«æ¥æºä¿¡æ¯"""
            formatted_docs = []
            for i, doc in enumerate(docs, 1):
                source = doc.metadata.get("source", "æœªçŸ¥")
                title = doc.metadata.get("title", "")
                score = doc.metadata.get("score", 0.0)

                doc_content = f"æ–‡æ¡£ {i} (æ¥æº: {source}, ç›¸ä¼¼åº¦: {score:.3f})\n"
                if title:
                    doc_content += f"æ ‡é¢˜: {title}\n"
                doc_content += f"å†…å®¹: {doc.page_content}"

                formatted_docs.append(doc_content)

            return "\n\n---\n\n".join(formatted_docs)

        chain = (
            {
                "context": retriever | format_docs_with_sources,
                "question": RunnablePassthrough()
            }
            | prompt
            | self.llm
            | StrOutputParser()
        )

        return chain

    def chat(self, kb_name: str, question: str, chain_type: str) -> str:
        """ä¸çŸ¥è¯†åº“å¯¹è¯"""
        chain = self.create_qa_chain(kb_name, chain_type)
        if not chain:
            return "æ— æ³•åˆ›å»ºé—®ç­”é“¾ï¼Œè¯·æ£€æŸ¥çŸ¥è¯†åº“é…ç½®"

        try:
            return chain.invoke(question)
        except Exception as e:
            return f"å›ç­”é—®é¢˜æ—¶å‡ºé”™: {e}"

# ========================
# æ¼”ç¤ºå‡½æ•°
# ========================

def demo_ragflow_langchain_integration():
    """æ¼”ç¤ºRAGFlow + LangChainé›†æˆ"""
    print("=" * 60)
    print("ğŸš€ RAGFlow + LangChain é›†æˆæ¼”ç¤º")
    print("=" * 60)

    # åˆ›å»ºåº”ç”¨å®ä¾‹
    app = RAGFlowLangChainApp(
        ragflow_url="http://localhost:9380",  # RAGFlowæœåŠ¡åœ°å€
        ragflow_api_key=os.getenv("RAGFLOW_API_KEY"),
        llm_model=os.getenv("LLM_MODEL", "GLM-4.5")  # ä»ç¯å¢ƒå˜é‡è·å–LLMæ¨¡å‹
    )

    # åˆå§‹åŒ–åº”ç”¨
    if not app.initialize():
        print("âŒ åº”ç”¨åˆå§‹åŒ–å¤±è´¥")
        return

    # é€‰æ‹©çŸ¥è¯†åº“
    if not app.available_kbs:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„çŸ¥è¯†åº“")
        print("è¯·å…ˆåœ¨RAGFlowä¸­åˆ›å»ºçŸ¥è¯†åº“å¹¶æ·»åŠ æ–‡æ¡£")
        return

    print(f"\nå¯ç”¨çŸ¥è¯†åº“æ•°é‡: {len(app.available_kbs)}")
    print("æ‰€æœ‰å¯ç”¨çŸ¥è¯†åº“:")
    for i, kb in enumerate(app.available_kbs, 1):
        if isinstance(kb, str):
            print(f"{i}. {kb}")
        elif isinstance(kb, dict):
            kb_id = kb.get('id', 'unknown')
            kb_name = kb.get('name', 'unknown')
            kb_desc = kb.get('description', 'æ— æè¿°')
            doc_count = kb.get('document_count', 0)
            chunk_count = kb.get('chunk_count', 0)
            print(f"{i}. {kb_name} (ID: {kb_id})")
            print(f"   æè¿°: {kb_desc}")
            print(f"   æ–‡æ¡£æ•°: {doc_count}, Chunkæ•°: {chunk_count}")
        else:
            print(f"{i}. {str(kb)}")

    print(f"\nğŸš€ ä½¿ç”¨æ‰€æœ‰çŸ¥è¯†åº“è¿›è¡Œæ£€ç´¢...")

    # åˆ›å»ºå¤šçŸ¥è¯†åº“æ£€ç´¢å™¨
    multi_retriever = app.create_multi_kb_retriever()
    print(f"âœ… å¤šçŸ¥è¯†åº“æ£€ç´¢å™¨åˆ›å»ºæˆåŠŸï¼ŒåŒ…å« {len(multi_retriever.retrievers)} ä¸ªçŸ¥è¯†åº“")

    # æµ‹è¯•æ£€ç´¢
    test_queries = [
        "ç‹ä¹¦å‹æ˜¯ä»€ä¹ˆå²—ä½?",
        "ç‹ä¹¦å‹ä¸Šå‘¨åšäº†ä»€ä¹ˆ",
        "æ€»ç»“è¿‘å‡ å‘¨ç‹ä¹¦å‹çš„å·¥ä½œå†…å®¹"
    ]

    print("\nğŸ“Š æµ‹è¯•å¤šçŸ¥è¯†åº“æ£€ç´¢åŠŸèƒ½:")
    for query in test_queries:
        print(f"\nğŸ” æŸ¥è¯¢: {query}")
        docs = multi_retriever.get_relevant_documents(query)

        print(f"ğŸ“‹ æ‰¾åˆ° {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£:")
        for i, doc in enumerate(docs, 1):
            score = doc.metadata.get("score", 0.0)
            source = doc.metadata.get("source", "æœªçŸ¥")
            kb_name = doc.metadata.get("knowledge_base", "æœªçŸ¥")
            title = doc.metadata.get("title", "")
            content_preview = doc.page_content[:100] + "..." if len(doc.page_content) > 100 else doc.page_content

            print(f"  {i}. [åˆ†æ•°: {score:.3f}] çŸ¥è¯†åº“: {kb_name}")
            if title:
                print(f"     æ ‡é¢˜: {title}")
            print(f"     æ¥æº: {source}")
            print(f"     å†…å®¹: {content_preview}")

    # æµ‹è¯•å¤šçŸ¥è¯†åº“é—®ç­”
    print("\nğŸ’¬ æµ‹è¯•å¤šçŸ¥è¯†åº“é—®ç­”åŠŸèƒ½:")

    # åˆ›å»ºå¤šçŸ¥è¯†åº“QAé“¾
    multi_kb_qa_chain = app.create_multi_kb_qa_chain(multi_retriever, chain_type="with_sources")

    for query in test_queries[:2]:  # åªæµ‹è¯•å‰ä¸¤ä¸ªé—®é¢˜
        print(f"\nâ“ é—®é¢˜: {query}")

        try:
            # å¤šçŸ¥è¯†åº“é—®ç­”
            answer = multi_kb_qa_chain.invoke(query)
            print(f"ğŸ¤– å¤šçŸ¥è¯†åº“å›ç­”:")
            print(answer)
        except Exception as e:
            print(f"âŒ å¤šçŸ¥è¯†åº“é—®ç­”å‡ºé”™: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("RAGFlow + LangChain é›†æˆæŒ‡å—")
    print("=" * 60)
    print("æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•åœ¨LangChainä¸­ä½¿ç”¨RAGFlowçš„çŸ¥è¯†åº“")

    while True:
        print("\n" + "=" * 60)
        print("é€‰æ‹©æ¼”ç¤ºåŠŸèƒ½ï¼š")
        print("=" * 60)
        print("1. RAGFlow + LangChain é›†æˆæ¼”ç¤º")
        print("2. æ•°æ®è¿ç§»åŠŸèƒ½æ¼”ç¤º")
        print("3. è¿æ¥æµ‹è¯•")
        print("0. é€€å‡º")

        choice = input("\nè¯·é€‰æ‹© (0-3): ").strip()

        if choice == "0":
            print("\næ„Ÿè°¢ä½¿ç”¨RAGFlow + LangChainé›†æˆæŒ‡å—ï¼")
            break
        elif choice == "1":
            demo_ragflow_langchain_integration()
        elif choice == "2":
            # è¿æ¥æµ‹è¯•
            connector = RAGFlowAPIConnector()
            if connector.test_connection():
                print("âœ… RAGFlowè¿æ¥æˆåŠŸ")
                kbs = connector.get_knowledge_bases()
                print(f"å‘ç° {len(kbs)} ä¸ªçŸ¥è¯†åº“")
                for kb in kbs:
                    # å¤„ç†çŸ¥è¯†åº“å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸çš„æƒ…å†µ
                    if isinstance(kb, str):
                        print(f"  - {kb}")
                    elif isinstance(kb, dict):
                        print(f"  - {kb.get('name', 'æœªçŸ¥')}")
                    else:
                        print(f"  - {str(kb)}")
            else:
                print("âŒ RAGFlowè¿æ¥å¤±è´¥")
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥0-3ä¹‹é—´çš„æ•°å­—")

if __name__ == "__main__":
    main()