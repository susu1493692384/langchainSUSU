# LangChain Memory å¿«é€ŸæŸ¥è¡¨

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºç¡€å¯¼å…¥
```python
from langchain_classic.memory import (
    ConversationBufferMemory,           # ç¼“å†²è®°å¿†
    ConversationBufferWindowMemory,     # çª—å£è®°å¿†
    ConversationSummaryMemory,          # æ‘˜è¦è®°å¿†
    ConversationKGMemory,               # çŸ¥è¯†å›¾è°±è®°å¿†
    VectorStoreRetrieverMemory          # å‘é‡è®°å¿†
)
from langchain_classic.chains import ConversationChain
from langchain_openai import ChatOpenAI
```

## ğŸ“‹ Memoryç±»å‹é€ŸæŸ¥

| ç±»å‹ | ç”¨é€” | è®°å¿†é•¿åº¦ | é€‚ç”¨åœºæ™¯ | é…ç½®å¤æ‚åº¦ |
|------|------|----------|----------|-----------|
| `ConversationBufferMemory` | å®Œæ•´å¯¹è¯ | æ— é™åˆ¶ | çŸ­æœŸèŠå¤© | â­ |
| `ConversationBufferWindowMemory` | æœ€è¿‘Nè½® | Nè½® | é•¿æœŸå¯¹è¯ | â­â­ |
| `ConversationSummaryMemory` | æ‘˜è¦ | æ™ºèƒ½æ‘˜è¦ | å¤§é‡å†å² | â­â­â­ |
| `ConversationKGMemory` | çŸ¥è¯†å›¾è°± | ç»“æ„åŒ– | çŸ¥è¯†å¯†é›† | â­â­â­â­ |
| `VectorStoreRetrieverMemory` | å‘é‡æ£€ç´¢ | æ— é™åˆ¶ | è¯­ä¹‰æœç´¢ | â­â­â­â­ |

## âš¡ å¸¸ç”¨é…ç½®æ¨¡æ¿

### 1. åŸºç¡€ç¼“å†²è®°å¿† â­
```python
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)
```

### 2. çª—å£è®°å¿† â­â­
```python
memory = ConversationBufferWindowMemory(
    k=5,                          # ä¿ç•™æœ€è¿‘5è½®
    memory_key="recent_history",
    return_messages=True
)
```

### 3. æ‘˜è¦è®°å¿† â­â­â­
```python
memory = ConversationSummaryMemory(
    llm=ChatOpenAI(model="gpt-3.5-turbo"),
    max_token_limit=800,
    memory_key="summary_history",
    return_messages=True
)
```

### 4. å‘é‡æ£€ç´¢è®°å¿† â­â­â­â­
```python
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

embeddings = OpenAIEmbeddings()
vectorstore = Chroma(embedding_function=embeddings)

memory = VectorStoreRetrieverMemory(
    retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
    memory_key="relevant_history"
)
```

## ğŸ”§ é€šç”¨å‚æ•°é€ŸæŸ¥

### åŸºç¡€å‚æ•°ï¼ˆæ‰€æœ‰Memoryé€šç”¨ï¼‰
```python
memory = AnyMemoryClass(
    memory_key="chat_history",        # åœ¨promptä¸­å¼•ç”¨çš„å˜é‡å
    return_messages=True,             # è¿”å›æ¶ˆæ¯å¯¹è±¡æ ¼å¼
    input_key="input",                # è¾“å…¥é”®å
    output_key="output",              # è¾“å‡ºé”®å
    human_prefix="Human",             # ç”¨æˆ·æ¶ˆæ¯å‰ç¼€
    ai_prefix="AI",                   # AIæ¶ˆæ¯å‰ç¼€
    verbose=False                     # æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
)
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| ç‰¹æ€§ | ç¼“å†²è®°å¿† | çª—å£è®°å¿† | æ‘˜è¦è®°å¿† | å‘é‡è®°å¿† |
|------|----------|----------|----------|----------|
| **å†…å­˜ä½¿ç”¨** | âŒ é«˜ | âœ… ä½ | âœ… ä½ | âœ… å¯æ§ |
| **ä¸Šä¸‹æ–‡å®Œæ•´æ€§** | âœ… å®Œæ•´ | âŒ æœ‰é™ | âš ï¸ æ‘˜è¦ | âœ… ç›¸å…³ |
| **æ£€ç´¢é€Ÿåº¦** | âœ… å¿« | âœ… å¿« | âœ… å¿« | âŒ æ…¢ |
| **Tokenæ¶ˆè€—** | âŒ é«˜ | âœ… ä½ | âœ… ä½ | âœ… ä½ |
| **å®ç°å¤æ‚åº¦** | â­ ç®€å• | â­ ç®€å• | â­â­ ä¸­ç­‰ | â­â­â­â­ å¤æ‚ |

## ğŸ¯ åœºæ™¯é€‰æ‹©æŒ‡å—

### çŸ­æœŸå¯¹è¯ (< 10è½®)
```python
# æ¨èï¼šç¼“å†²è®°å¿†
memory = ConversationBufferMemory(
    return_messages=True,
    memory_key="chat_history"
)
```

### é•¿æœŸèŠå¤© (> 10è½®)
```python
# æ¨èï¼šçª—å£è®°å¿†
memory = ConversationBufferWindowMemory(
    k=5,                              # åªä¿ç•™æœ€è¿‘5è½®
    return_messages=True
)
```

### çŸ¥è¯†é—®ç­”/æ–‡æ¡£å¯¹è¯
```python
# æ¨èï¼šæ‘˜è¦è®°å¿†
memory = ConversationSummaryMemory(
    llm=ChatOpenAI(model="gpt-3.5-turbo"),
    max_token_limit=1000,
    return_messages=True
)
```

### å¤§è§„æ¨¡å¯¹è¯å†å²
```python
# æ¨èï¼šå‘é‡è®°å¿†
memory = VectorStoreRetrieverMemory(
    retriever=vectorstore.as_retriever(search_kwargs={"k": 5}),
    memory_key="relevant_history"
)
```

## ğŸ”¥ å¿«é€Ÿé…ç½®ä»£ç 

### æœ€ç®€å•é…ç½®ï¼ˆå¤åˆ¶å³ç”¨ï¼‰
```python
from langchain_classic.memory import ConversationBufferMemory
from langchain_classic.chains import ConversationChain
from langchain_openai import ChatOpenAI

# 1. åˆ›å»ºè®°å¿†
memory = ConversationBufferMemory()

# 2. åˆ›å»ºå¯¹è¯é“¾
conversation = ConversationChain(
    llm=ChatOpenAI(model="gpt-3.5-turbo"),
    memory=memory,
    verbose=False
)

# 3. å¼€å§‹å¯¹è¯
response = conversation.predict(input="ä½ å¥½ï¼")
print(response)

# 4. ç»§ç»­å¯¹è¯ï¼ˆè‡ªåŠ¨è®°ä½ä¸Šä¸‹æ–‡ï¼‰
response = conversation.predict(input="åˆšæ‰æˆ‘è¯´äº†ä»€ä¹ˆï¼Ÿ")
print(response)  # AIä¼šè®°ä½ä¹‹å‰çš„å¯¹è¯
```

### å¸¸ç”¨é…ç½®æ¨¡æ¿
```python
# é…ç½®1ï¼šçª—å£è®°å¿†ï¼ˆæ¨èç”¨äºé•¿æœŸå¯¹è¯ï¼‰
def create_window_memory(k=5):
    return ConversationBufferWindowMemory(
        k=k,
        return_messages=True,
        memory_key="chat_history"
    )

# é…ç½®2ï¼šæ‘˜è¦è®°å¿†ï¼ˆæ¨èç”¨äºæ–‡æ¡£å¯¹è¯ï¼‰
def create_summary_memory(llm_model="gpt-3.5-turbo"):
    return ConversationSummaryMemory(
        llm=ChatOpenAI(model=llm_model),
        max_token_limit=800,
        return_messages=True,
        memory_key="summary"
    )

# é…ç½®3ï¼šå¸¦è‡ªå®šä¹‰å‰ç¼€çš„ç¼“å†²è®°å¿†
def create_custom_memory():
    return ConversationBufferMemory(
        return_messages=True,
        memory_key="conversation",
        human_prefix="ç”¨æˆ·",
        ai_prefix="åŠ©æ‰‹"
    )
```

## ğŸ› ï¸ å¸¸ç”¨æ“ä½œæ–¹æ³•

### æŸ¥çœ‹è®°å¿†å†…å®¹
```python
# æŸ¥çœ‹æ‰€æœ‰æ¶ˆæ¯
for message in memory.chat_memory.messages:
    print(f"{message.type}: {message.content}")

# æŸ¥çœ‹ç¼“å†²åŒºå†…å®¹ï¼ˆä»…ç¼“å†²è®°å¿†ï¼‰
print(memory.buffer)

# æŸ¥çœ‹æ¶ˆæ¯æ•°é‡
print(f"æ¶ˆæ¯æ€»æ•°: {len(memory.chat_memory.messages)}")
```

### æ¸…ç©ºè®°å¿†
```python
# æ¸…ç©ºæ‰€æœ‰è®°å¿†
memory.clear()

# æ‰‹åŠ¨ç§»é™¤æœ€åä¸€æ¡æ¶ˆæ¯
memory.chat_memory.messages.pop()
```

### æ‰‹åŠ¨æ·»åŠ æ¶ˆæ¯
```python
from langchain_core.messages import HumanMessage, AIMessage

# æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
memory.chat_memory.add_user_message("è¿™æ˜¯ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯")

# æ·»åŠ AIå›å¤
memory.chat_memory.add_ai_message("è¿™æ˜¯ä¸€æ¡AIå›å¤")
```

## ğŸš¨ å¸¸è§é”™è¯¯è§£å†³

### é”™è¯¯1ï¼šModuleNotFoundError
```python
# é”™è¯¯å†™æ³•
from langchain.memory import ConversationBufferMemory

# æ­£ç¡®å†™æ³•
from langchain_classic.memory import ConversationBufferMemory
```

### é”™è¯¯2ï¼šè®°å¿†é•¿åº¦è¿‡é•¿
```python
# è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨çª—å£è®°å¿†
memory = ConversationBufferWindowMemory(k=10)  # é™åˆ¶ä¸º10è½®

# æˆ–ä½¿ç”¨æ‘˜è¦è®°å¿†
memory = ConversationSummaryMemory(max_token_limit=500)
```

### é”™è¯¯3ï¼šTokenè¶…é™
```python
# è§£å†³æ–¹æ¡ˆï¼šè®¾ç½®æ‘˜è¦è®°å¿†çš„tokené™åˆ¶
memory = ConversationSummaryMemory(
    llm=llm,
    max_token_limit=1000  # é™åˆ¶æ‘˜è¦é•¿åº¦
)
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### 1. é€‰æ‹©åˆé€‚çš„Memoryç±»å‹
- **< 5è½®å¯¹è¯**: ä½¿ç”¨ `ConversationBufferMemory`
- **5-20è½®å¯¹è¯**: ä½¿ç”¨ `ConversationBufferWindowMemory(k=10)`
- **> 20è½®å¯¹è¯**: ä½¿ç”¨ `ConversationSummaryMemory`

### 2. ä¼˜åŒ–Tokenä½¿ç”¨
```python
# è®¾ç½®åˆç†çš„çª—å£å¤§å°
memory = ConversationBufferWindowMemory(k=5)  # 5è½®é€šå¸¸å¤Ÿç”¨

# æˆ–é™åˆ¶æ‘˜è¦é•¿åº¦
memory = ConversationSummaryMemory(
    llm=llm,
    max_token_limit=500  # æ ¹æ®æ¨¡å‹é™åˆ¶è°ƒæ•´
)
```

### 3. å¼‚æ­¥æ“ä½œï¼ˆé«˜çº§ï¼‰
```python
import asyncio

async def async_conversation():
    memory = ConversationBufferMemory()

    # å¼‚æ­¥å¤„ç†å¯¹è¯
    tasks = []
    for i in range(5):
        task = asyncio.create_task(
            process_async_input(memory, f"æ¶ˆæ¯ {i}")
        )
        tasks.append(task)

    await asyncio.gather(*tasks)
    return memory

async def process_async_input(memory, user_input):
    # æ¨¡æ‹Ÿå¼‚æ­¥å¤„ç†
    await asyncio.sleep(0.1)
    memory.chat_memory.add_user_message(user_input)
    memory.chat_memory.add_ai_message(f"å›å¤: {user_input}")
```

## ğŸ” è°ƒè¯•æŠ€å·§

### å¯ç”¨è¯¦ç»†æ—¥å¿—
```python
# åˆ›å»ºè®°å¿†æ—¶å¯ç”¨verbose
memory = ConversationBufferMemory(
    return_messages=True,
    verbose=True  # æ˜¾ç¤ºè¯¦ç»†æ“ä½œæ—¥å¿—
)

# æˆ–åœ¨å¯¹è¯é“¾ä¸­å¯ç”¨
conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=True  # æ˜¾ç¤ºå¯¹è¯è¯¦ç»†è¿‡ç¨‹
)
```

### æ£€æŸ¥è®°å¿†çŠ¶æ€
```python
def debug_memory(memory):
    print(f"=== {memory.__class__.__name__} è°ƒè¯•ä¿¡æ¯ ===")
    print(f"æ¶ˆæ¯æ•°é‡: {len(memory.chat_memory.messages)}")

    # æ˜¾ç¤ºæœ€è¿‘5æ¡æ¶ˆæ¯
    recent_messages = memory.chat_memory.messages[-5:]
    for i, msg in enumerate(recent_messages, 1):
        print(f"{i}. [{msg.type}]: {msg.content[:50]}...")

    print("=" * 50)

# ä½¿ç”¨è°ƒè¯•
debug_memory(memory)
```

## ğŸ“š å®Œæ•´ç¤ºä¾‹æ¨¡æ¿

### å®Œæ•´çš„èŠå¤©æœºå™¨äºº
```python
def create_chatbot(memory_type="buffer", **kwargs):
    """
    åˆ›å»ºèŠå¤©æœºå™¨äºº

    Args:
        memory_type: "buffer", "window", "summary", "vector"
        **kwargs: è®°å¿†ç‰¹å®šå‚æ•°

    Returns:
        ConversationChain: é…ç½®å¥½çš„å¯¹è¯é“¾
    """
    llm = ChatOpenAI(model="gpt-3.5-turbo")

    # é€‰æ‹©è®°å¿†ç±»å‹
    if memory_type == "buffer":
        memory = ConversationBufferMemory(
            return_messages=True,
            **kwargs
        )
    elif memory_type == "window":
        memory = ConversationBufferWindowMemory(
            k=kwargs.get('k', 5),
            return_messages=True
        )
    elif memory_type == "summary":
        memory = ConversationSummaryMemory(
            llm=llm,
            max_token_limit=kwargs.get('max_token_limit', 800),
            return_messages=True
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„memory_type: {memory_type}")

    # åˆ›å»ºå¯¹è¯é“¾
    return ConversationChain(
        llm=llm,
        memory=memory,
        verbose=False
    )

# ä½¿ç”¨ç¤ºä¾‹
chatbot = create_chatbot("window", k=3)
response = chatbot.predict(input="ä½ å¥½ï¼Œè¯·è®°ä½æˆ‘çš„åå­—æ˜¯å°æ˜")
print(response)

response = chatbot.predict(input="æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ")
print(response)  # åº”è¯¥å›ç­”"å°æ˜"
```

## ğŸ¯ æ€»ç»“

### å¿«é€Ÿé€‰æ‹©æŒ‡å—
- **æ–°æ‰‹å…¥é—¨** â†’ `ConversationBufferMemory`
- **é•¿æœŸå¯¹è¯** â†’ `ConversationBufferWindowMemory(k=5)`
- **æ–‡æ¡£å¯¹è¯** â†’ `ConversationSummaryMemory`
- **è¯­ä¹‰æœç´¢** â†’ `VectorStoreRetrieverMemory`

### æœ€ä½³å®è·µ
1. ä¼˜å…ˆè€ƒè™‘ä½¿ç”¨çª—å£è®°å¿†ï¼ˆå¹³è¡¡æ€§èƒ½å’ŒåŠŸèƒ½ï¼‰
2. è®¾ç½®åˆé€‚çš„tokené™åˆ¶
3. å¯ç”¨verboseæ¨¡å¼è¿›è¡Œè°ƒè¯•
4. å®šæœŸæ¸…ç†ä¸å¿…è¦çš„è®°å¿†
5. é€‰æ‹©é€‚åˆåº”ç”¨åœºæ™¯çš„è®°å¿†ç±»å‹

### æ€§èƒ½è­¦å‘Š
- âš ï¸ ç¼“å†²è®°å¿†ä¼šæ— é™å¢é•¿
- âš ï¸ å¤§é‡å†å²å¯¹è¯è€ƒè™‘ä½¿ç”¨å‘é‡è®°å¿†
- âš ï¸ æ³¨æ„APIè°ƒç”¨æˆæœ¬å’Œtokené™åˆ¶