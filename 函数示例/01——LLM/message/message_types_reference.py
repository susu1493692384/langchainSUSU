#!/usr/bin/env python3
"""
LangChain æ¶ˆæ¯ç±»å‹å®Œæ•´å‚è€ƒæŒ‡å—
å±•ç¤º ChatOpenAI.invoke() æ–¹æ³•ä¸­ message å‚æ•°å¯ä»¥ä½¿ç”¨çš„æ‰€æœ‰æ¶ˆæ¯ç±»å‹

ä½œè€…: Claude
ç‰ˆæœ¬: 1.0
æ›´æ–°æ—¶é—´: 2025-11-28
"""

import os
from dotenv import load_dotenv
from langchain_core.messages import (
    HumanMessage,           # äººç±»æ¶ˆæ¯
    AIMessage,             # AIåŠ©æ‰‹æ¶ˆæ¯
    SystemMessage,         # ç³»ç»Ÿæ¶ˆæ¯
    FunctionMessage,       # å‡½æ•°è°ƒç”¨ç»“æœæ¶ˆæ¯(å·²å¼ƒç”¨)
    ToolMessage,           # å·¥å…·è°ƒç”¨ç»“æœæ¶ˆæ¯
    ChatMessage,           # é€šç”¨èŠå¤©æ¶ˆæ¯
)
from langchain_core.messages.message import Message
from langchain_openai import ChatOpenAI

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ================================
# 1. åŸºç¡€æ¶ˆæ¯ç±»å‹
# ================================

def basic_message_types():
    """å±•ç¤ºåŸºç¡€æ¶ˆæ¯ç±»å‹ï¼šHumanMessage, AIMessage, SystemMessage"""
    print("ğŸ“ === åŸºç¡€æ¶ˆæ¯ç±»å‹ç¤ºä¾‹ ===\n")

    llm = ChatOpenAI(
        model="glm-4",
        temperature=0.7,
        max_tokens=150,
        openai_api_key=os.getenv("GLM_API_KEY"),
        openai_api_base=os.getenv("GLM_BASE_URL")
    )

    # 1. äººç±»æ¶ˆæ¯ - ç”¨æˆ·è¾“å…¥
    human_message = HumanMessage(content="ä½ å¥½ï¼è¯·ç”¨ä¸­æ–‡ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚")

    # 2. ç³»ç»Ÿæ¶ˆæ¯ - å®šä¹‰AIè¡Œä¸º
    system_message = SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonç¼–ç¨‹åŠ©æ‰‹ï¼Œå›ç­”è¦ç®€æ´æ˜äº†ã€‚")

    # 3. AIæ¶ˆæ¯ - ä¹‹å‰çš„AIå›å¤
    ai_message = AIMessage(content="æˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ä½ è§£å†³ç¼–ç¨‹é—®é¢˜ã€‚")

    # å•ç‹¬ä½¿ç”¨äººç±»æ¶ˆæ¯
    try:
        print("ğŸ‘¤ ä»…æœ‰HumanMessage:")
        response = llm.invoke([human_message])
        print(f"å›ç­”: {response.content}\n")
    except Exception as e:
        print(f"é”™è¯¯: {e}\n")

    # ç»„åˆä½¿ç”¨æ¶ˆæ¯
    try:
        print("ğŸ¤– ç»„åˆæ¶ˆæ¯ (System + Human):")
        messages = [system_message, human_message]
        response = llm.invoke(messages)
        print(f"ç³»ç»ŸæŒ‡ä»¤: {system_message.content}")
        print(f"ç”¨æˆ·é—®é¢˜: {human_message.content}")
        print(f"AIå›ç­”: {response.content}\n")
    except Exception as e:
        print(f"é”™è¯¯: {e}\n")

    # å¤šè½®å¯¹è¯
    try:
        print("ğŸ’¬ å¤šè½®å¯¹è¯:")
        conversation = [
            system_message,
            HumanMessage(content="ä»€ä¹ˆæ˜¯Pythonï¼Ÿ"),
            AIMessage(content="Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ã€‚"),
            HumanMessage(content="Pythonæœ‰å“ªäº›ä¼˜ç‚¹ï¼Ÿ")
        ]
        response = llm.invoke(conversation)
        print(f"å¯¹è¯å†å²:")
        for i, msg in enumerate(conversation):
            msg_type = type(msg).__name__
            print(f"  {i+1}. {msg_type}: {msg.content}")
        print(f"AIæœ€æ–°å›ç­”: {response.content}\n")
    except Exception as e:
        print(f"é”™è¯¯: {e}\n")

# ================================
# 2. å¸¦å…ƒæ•°æ®çš„æ¶ˆæ¯
# ================================

def messages_with_metadata():
    """å±•ç¤ºå¸¦å…ƒæ•°æ®çš„æ¶ˆæ¯"""
    print("ğŸ·ï¸ === å¸¦å…ƒæ•°æ®çš„æ¶ˆæ¯ç¤ºä¾‹ ===\n")

    llm = ChatOpenAI(
        model="glm-4",
        temperature=0.7,
        max_tokens=100,
        openai_api_key=os.getenv("GLM_API_KEY"),
        openai_api_base=os.getenv("GLM_BASE_URL")
    )

    # å¸¦åç§°çš„äººç±»æ¶ˆæ¯
    human_with_name = HumanMessage(
        content="å¸®æˆ‘åˆ†æä¸€ä¸‹è¿™æ®µä»£ç çš„æ€§èƒ½",
        name="user_001",  # ç”¨æˆ·æ ‡è¯†
        additional_kwargs={"priority": "high"}  # é¢å¤–å…ƒæ•°æ®
    )

    # å¸¦å·¥å…·è°ƒç”¨ä¿¡æ¯çš„AIæ¶ˆæ¯
    ai_with_tools = AIMessage(
        content="æˆ‘æ¥å¸®ä½ åˆ†æä»£ç æ€§èƒ½ã€‚",
        tool_calls=[
            {
                "id": "call_001",
                "type": "function",
                "function": {
                    "name": "analyze_code",
                    "arguments": '{"code": "sample_code"}'
                }
            }
        ]
    )

    try:
        print("ğŸ”§ å¸¦å…ƒæ•°æ®çš„æ¶ˆæ¯:")
        messages = [human_with_name]
        response = llm.invoke(messages)

        print(f"ç”¨æˆ·: {human_with_name.content}")
        print(f"ç”¨æˆ·ID: {human_with_name.name}")
        print(f"å…ƒæ•°æ®: {human_with_name.additional_kwargs}")
        print(f"AIå›ç­”: {response.content}\n")

        print("ğŸ› ï¸ å¸¦å·¥å…·è°ƒç”¨çš„AIæ¶ˆæ¯:")
        print(f"AI: {ai_with_tools.content}")
        print(f"å·¥å…·è°ƒç”¨: {ai_with_tools.tool_calls}\n")
    except Exception as e:
        print(f"é”™è¯¯: {e}\n")

# ================================
# 3. å·¥å…·æ¶ˆæ¯ç±»å‹
# ================================

def tool_message_types():
    """å±•ç¤ºå·¥å…·ç›¸å…³çš„æ¶ˆæ¯ç±»å‹"""
    print("ğŸ”§ === å·¥å…·æ¶ˆæ¯ç±»å‹ç¤ºä¾‹ ===\n")

    llm = ChatOpenAI(
        model="glm-4",
        temperature=0.7,
        max_tokens=100,
        openai_api_key=os.getenv("GLM_API_KEY"),
        openai_api_base=os.getenv("GLM_BASE_URL")
    )

    # å·¥å…·è°ƒç”¨æ¶ˆæ¯
    ai_tool_call = AIMessage(
        content="æˆ‘æ¥ä¸ºä½ è®¡ç®—ä¸€äº›æ•°æ®ã€‚",
        tool_calls=[
            {
                "id": "calc_001",
                "type": "function",
                "function": {
                    "name": "calculate",
                    "arguments": '{"expression": "2+2"}'
                }
            }
        ]
    )

    # å·¥å…·æ‰§è¡Œç»“æœæ¶ˆæ¯
    tool_result = ToolMessage(
        content="4",
        tool_call_id="calc_001",
        name="calculate"
    )

    try:
        print("âš¡ å·¥å…·è°ƒç”¨æµç¨‹:")
        messages = [
            HumanMessage(content="è®¡ç®—2+2ç­‰äºå¤šå°‘ï¼Ÿ"),
            ai_tool_call,
            tool_result,
            HumanMessage(content="è¯·è§£é‡Šè®¡ç®—ç»“æœã€‚")
        ]

        response = llm.invoke(messages)

        print("å¯¹è¯æµç¨‹:")
        for i, msg in enumerate(messages):
            msg_type = type(msg).__name__
            if hasattr(msg, 'tool_call_id'):
                print(f"  {i+1}. {msg_type}: {msg.content} (å·¥å…·ID: {msg.tool_call_id})")
            else:
                print(f"  {i+1}. {msg_type}: {msg.content}")

        print(f"æœ€ç»ˆå›ç­”: {response.content}\n")
    except Exception as e:
        print(f"é”™è¯¯: {e}\n")

# ================================
# 4. é€šç”¨èŠå¤©æ¶ˆæ¯
# ================================

def chat_message_types():
    """å±•ç¤ºé€šç”¨ChatMessageç±»å‹"""
    print("ğŸ’¬ === é€šç”¨èŠå¤©æ¶ˆæ¯ç¤ºä¾‹ ===\n")

    llm = ChatOpenAI(
        model="glm-4",
        temperature=0.7,
        max_tokens=100,
        openai_api_key=os.getenv("GLM_API_KEY"),
        openai_api_base=os.getenv("GLM_BASE_URL")
    )

    # ä½¿ç”¨ChatMessageåˆ›å»ºä¸åŒè§’è‰²çš„æ¶ˆæ¯
    developer_msg = ChatMessage(
        role="developer",
        content="è¯·ç¡®ä¿ä»£ç ç¬¦åˆæœ€ä½³å®è·µã€‚"
    )

    reviewer_msg = ChatMessage(
        role="reviewer",
        content="ä»£ç çœ‹èµ·æ¥ä¸é”™ï¼Œä½†å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚"
    )

    assistant_msg = ChatMessage(
        role="assistant",
        content="æˆ‘ç†è§£äº†ï¼Œä¼šæŒ‰ç…§æœ€ä½³å®è·µæ¥ä¼˜åŒ–ä»£ç ã€‚"
    )

    try:
        print("ğŸ­ é€šç”¨èŠå¤©æ¶ˆæ¯:")
        messages = [
            developer_msg,
            reviewer_msg,
            HumanMessage(content="è¯·é‡å†™è¿™æ®µä»£ç ã€‚")
        ]

        response = llm.invoke(messages)

        for msg in messages:
            print(f"{msg.role}: {msg.content}")

        print(f"AIå›ç­”: {response.content}\n")
    except Exception as e:
        print(f"é”™è¯¯: {e}\n")

# ================================
# 5. æ¶ˆæ¯åˆ—è¡¨çš„ä¸åŒç»„ç»‡æ–¹å¼
# ================================

def message_organization_examples():
    """å±•ç¤ºæ¶ˆæ¯åˆ—è¡¨çš„ä¸åŒç»„ç»‡æ–¹å¼"""
    print("ğŸ“‹ === æ¶ˆæ¯ç»„ç»‡æ–¹å¼ç¤ºä¾‹ ===\n")

    llm = ChatOpenAI(
        model="glm-4",
        temperature=0.7,
        max_tokens=150,
        openai_api_key=os.getenv("GLM_API_KEY"),
        openai_api_base=os.getenv("GLM_BASE_URL")
    )

    # æ–¹å¼1: ç®€å•å•è½®å¯¹è¯
    simple_chat = [HumanMessage(content="ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ")]

    # æ–¹å¼2: å¸¦ç³»ç»ŸæŒ‡ä»¤çš„å¯¹è¯
    system_guided = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªAIä¸“å®¶ï¼Œç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡ŠæŠ€æœ¯æ¦‚å¿µã€‚"),
        HumanMessage(content="è§£é‡Šä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œã€‚")
    ]

    # æ–¹å¼3: å¤šè½®å¯¹è¯å†å²
    conversation_history = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹è€å¸ˆã€‚"),
        HumanMessage(content="ä»€ä¹ˆæ˜¯å˜é‡ï¼Ÿ"),
        AIMessage(content="å˜é‡æ˜¯ç”¨æ¥å­˜å‚¨æ•°æ®çš„å®¹å™¨ã€‚"),
        HumanMessage(content="å¦‚ä½•åœ¨Pythonä¸­å®šä¹‰å˜é‡ï¼Ÿ"),
        AIMessage(content="åœ¨Pythonä¸­ï¼Œå¯ä»¥ä½¿ç”¨èµ‹å€¼è¯­å¥å®šä¹‰å˜é‡ï¼Œå¦‚ï¼šx = 10"),
        HumanMessage(content="å¯ä»¥ç»™æˆ‘æ›´å¤šä¾‹å­å—ï¼Ÿ")
    ]

    # æ–¹å¼4: è§’è‰²æ‰®æ¼”å¯¹è¯
    role_playing = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªåŒ»ç”Ÿï¼Œç”¨æˆ·æ˜¯ç—…äººã€‚"),
        HumanMessage(content="åŒ»ç”Ÿï¼Œæˆ‘æœ€è¿‘æ€»æ˜¯å¤´ç—›ï¼Œè¯¥æ€ä¹ˆåŠï¼Ÿ")
    ]

    # æ–¹å¼5: å¤šä¸“å®¶è®¨è®º
    expert_discussion = [
        SystemMessage(content="ç°åœ¨æœ‰ä¸‰ä¸ªä¸“å®¶è®¨è®ºä¸€ä¸ªé—®é¢˜ã€‚"),
        ChatMessage(role="frontend_developer", content="æˆ‘ä»¬éœ€è¦ä¼˜åŒ–é¡µé¢åŠ è½½é€Ÿåº¦ã€‚"),
        ChatMessage(role="backend_developer", content="åç«¯APIå“åº”æ—¶é—´éœ€è¦ä¼˜åŒ–ã€‚"),
        ChatMessage(role="devops", content="æœåŠ¡å™¨é…ç½®ä¹Ÿéœ€è¦è°ƒæ•´ã€‚"),
        HumanMessage(content="ç»¼åˆæ¥çœ‹ï¼Œæˆ‘ä»¬åº”è¯¥ä»å“ªæ–¹é¢å¼€å§‹ä¼˜åŒ–ï¼Ÿ")
    ]

    examples = [
        ("ç®€å•å•è½®å¯¹è¯", simple_chat),
        ("å¸¦ç³»ç»ŸæŒ‡ä»¤", system_guided),
        ("å¤šè½®å¯¹è¯", conversation_history),
        ("è§’è‰²æ‰®æ¼”", role_playing),
        ("å¤šä¸“å®¶è®¨è®º", expert_discussion)
    ]

    for name, messages in examples:
        try:
            print(f"ğŸ¯ {name}:")
            print("å¯¹è¯å†å²:")
            for i, msg in enumerate(messages):
                msg_type = type(msg).__name__
                if hasattr(msg, 'role'):
                    role = msg.role
                else:
                    role = msg_type.replace('Message', '')
                print(f"  {i+1}. {role}: {msg.content}")

            response = llm.invoke(messages)
            print(f"AIå›ç­”: {response.content}")
            print("-" * 50)
        except Exception as e:
            print(f"é”™è¯¯: {e}")
        print()

# ================================
# 6. ç‰¹æ®Šç”¨æ³•ç¤ºä¾‹
# ================================

def special_usage_examples():
    """å±•ç¤ºæ¶ˆæ¯çš„ç‰¹æ®Šç”¨æ³•"""
    print("âœ¨ === ç‰¹æ®Šç”¨æ³•ç¤ºä¾‹ ===\n")

    llm = ChatOpenAI(
        model="glm-4",
        temperature=0.7,
        max_tokens=150,
        openai_api_key=os.getenv("GLM_API_KEY"),
        openai_api_base=os.getenv("GLM_BASE_URL")
    )

    # 1. åŒ…å«ä»£ç å’Œè¯´æ˜
    code_message = HumanMessage(content="""
è¯·å¸®æˆ‘åˆ†æè¿™æ®µPythonä»£ç ï¼š

```python
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)
```

è¿™æ®µä»£ç æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿå¦‚ä½•ä¼˜åŒ–ï¼Ÿ
""")

    # 2. åŒ…å«å¤šè¯­è¨€å†…å®¹
    multilingual_message = HumanMessage(content="""
Hello! Can you help me with programming?
ä½ å¥½ï¼ä½ èƒ½å¸®æˆ‘ç¼–ç¨‹å—ï¼Ÿ
ã“ã‚“ã«ã¡ã¯ï¼ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚’æ‰‹ä¼ã£ã¦ãã‚Œã¾ã™ã‹ï¼Ÿ

è¯·ç”¨ä¸­æ–‡å›ç­”æˆ‘å…³äºç¼–ç¨‹çš„é—®é¢˜ã€‚
""")

    # 3. åŒ…å«ç»“æ„åŒ–æ•°æ®
    structured_message = HumanMessage(content="""
æˆ‘æœ‰ä¸€ä¸ªJSONæ•°æ®ï¼š
```json
{
    "name": "å¼ ä¸‰",
    "age": 25,
    "skills": ["Python", "JavaScript", "SQL"],
    "experience": 3
}
```

è¯·æ ¹æ®è¿™ä¸ªæ•°æ®ç”Ÿæˆä¸€ä¸ªä¸ªäººç®€ä»‹ã€‚
""")

    # 4. åŒ…å«æŒ‡ä»¤å’Œä¸Šä¸‹æ–‡
    instruction_message = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯é¢è¯•å®˜ã€‚"),
        HumanMessage(content="""
å€™é€‰äººä¿¡æ¯ï¼š
- åº”è˜å²—ä½ï¼šPythonå¼€å‘å·¥ç¨‹å¸ˆ
- å·¥ä½œç»éªŒï¼š2å¹´
- æŠ€æœ¯æ ˆï¼šPython, Django, MySQL, Redis

è¯·è®¾è®¡3ä¸ªåˆé€‚çš„æŠ€æœ¯é¢è¯•é—®é¢˜ã€‚
""")
    ]

    special_messages = [
        ("ä»£ç åˆ†æ", [code_message]),
        ("å¤šè¯­è¨€æ”¯æŒ", [multilingual_message]),
        ("ç»“æ„åŒ–æ•°æ®å¤„ç†", [structured_message]),
        ("é¢è¯•å®˜è§’è‰²", instruction_message)
    ]

    for name, messages in special_messages:
        try:
            print(f"ğŸš€ {name}:")
            print("è¾“å…¥:")
            for msg in messages:
                print(f"  {msg.content}")

            response = llm.invoke(messages)
            print(f"è¾“å‡º:\n{response.content}")
            print("-" * 50)
        except Exception as e:
            print(f"é”™è¯¯: {e}")
        print()

# ================================
# 7. é”™è¯¯å¤„ç†å’Œæœ€ä½³å®è·µ
# ================================

def best_practices():
    """å±•ç¤ºæ¶ˆæ¯ä½¿ç”¨çš„æœ€ä½³å®è·µ"""
    print("âœ… === æœ€ä½³å®è·µç¤ºä¾‹ ===\n")

    llm = ChatOpenAI(
        model="glm-4",
        temperature=0.7,
        max_tokens=100,
        openai_api_key=os.getenv("GLM_API_KEY"),
        openai_api_base=os.getenv("GLM_BASE_URL")
    )

    # âœ… å¥½çš„åšæ³•1: æ¸…æ™°çš„ç³»ç»Ÿæ¶ˆæ¯
    good_system = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªPythonç¼–ç¨‹ä¸“å®¶ã€‚å›ç­”è¦å‡†ç¡®ã€ç®€æ´ï¼Œå¹¶åŒ…å«ä»£ç ç¤ºä¾‹ã€‚"),
        HumanMessage(content="å¦‚ä½•åœ¨Pythonä¸­è¯»å–æ–‡ä»¶ï¼Ÿ")
    ]

    # âœ… å¥½çš„åšæ³•2: åˆç†çš„å¯¹è¯é•¿åº¦
    good_length = [
        SystemMessage(content="ç®€æ´å›ç­”é—®é¢˜ã€‚"),
        HumanMessage(content="ä»€ä¹ˆæ˜¯åˆ—è¡¨æ¨å¯¼å¼ï¼Ÿ")
    ]

    # âŒ åçš„åšæ³•1: ç¼ºå°‘ç³»ç»Ÿæ¶ˆæ¯
    bad_no_system = [
        HumanMessage(content="è¯·å‘Šè¯‰æˆ‘å¦‚ä½•å¼€å‘ä¸€ä¸ªå®Œæ•´çš„ç”µå•†ç³»ç»Ÿï¼ŒåŒ…æ‹¬å‰ç«¯ã€åç«¯ã€æ•°æ®åº“è®¾è®¡ã€éƒ¨ç½²ç­‰æ‰€æœ‰ç»†èŠ‚ã€‚")
    ]

    # âŒ åçš„åšæ³•2: æ¶ˆæ¯è¿‡é•¿
    bad_too_long = [
        HumanMessage(content="è¯·è¯¦ç»†è§£é‡Š" + "è¯¦ç»†" * 1000 + "çš„æ¦‚å¿µã€‚")
    ]

    practices = [
        ("âœ… å¥½çš„åšæ³•ï¼šæ¸…æ™°çš„ç³»ç»Ÿæ¶ˆæ¯", good_system),
        ("âœ… å¥½çš„åšæ³•ï¼šåˆç†çš„å¯¹è¯é•¿åº¦", good_length),
        ("âŒ åçš„åšæ³•ï¼šç¼ºå°‘ç³»ç»Ÿæ¶ˆæ¯", bad_no_system),
        ("âŒ åçš„åšæ³•ï¼šæ¶ˆæ¯è¿‡é•¿", bad_too_long)
    ]

    for name, messages in practices:
        try:
            print(f"{name}:")
            print(f"è¾“å…¥: {messages[0].content[:50]}...")

            response = llm.invoke(messages)
            print(f"è¾“å‡º: {response.content[:100]}...")
            print()
        except Exception as e:
            print(f"æ‰§è¡Œå¤±è´¥: {e}")
        print()

    # æœ€ä½³å®è·µå»ºè®®
    print("ğŸ’¡ æœ€ä½³å®è·µå»ºè®®:")
    print("1. å§‹ç»ˆä½¿ç”¨SystemMessageå®šä¹‰AIçš„è§’è‰²å’Œè¡Œä¸º")
    print("2. ä¿æŒæ¶ˆæ¯å†…å®¹ç®€æ´æ˜äº†ï¼Œé¿å…å†—é•¿")
    print("3. ä½¿ç”¨é€‚å½“çš„è§’è‰²æ‰®æ¼”æ¥è·å¾—æ›´å¥½çš„å›ç­”")
    print("4. å¯¹äºå¤æ‚ä»»åŠ¡ï¼Œå¯ä»¥åˆ†æ­¥éª¤æé—®")
    print("5. åˆç†ä½¿ç”¨å·¥å…·è°ƒç”¨æ¥æ‰©å±•AIçš„èƒ½åŠ›")
    print("6. æ³¨æ„æ¶ˆæ¯çš„ä¸Šä¸‹æ–‡è¿è´¯æ€§")
    print("7. é¿å…åœ¨ä¸€ä¸ªæ¶ˆæ¯ä¸­åŒ…å«è¿‡å¤šä¸ç›¸å…³çš„å†…å®¹")

# ================================
# ä¸»å‡½æ•°
# ================================

def main():
    """ä¸»å‡½æ•° - è¿è¡Œæ‰€æœ‰æ¶ˆæ¯ç±»å‹ç¤ºä¾‹"""
    import sys
    import io

    # è®¾ç½®UTF-8ç¼–ç è¾“å‡º
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

    print("ğŸ’¬ LangChain æ¶ˆæ¯ç±»å‹å®Œæ•´å‚è€ƒæŒ‡å—")
    print("=" * 60)
    print()

    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv("GLM_API_KEY") or not os.getenv("GLM_BASE_URL"):
        print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°GLM_API_KEYæˆ–GLM_BASE_URLç¯å¢ƒå˜é‡")
        print("è¯·ç¡®ä¿åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®äº†æ­£ç¡®çš„æ™ºè°±AI APIé…ç½®")
        print()
        return

    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    examples = [
        ("åŸºç¡€æ¶ˆæ¯ç±»å‹", basic_message_types),
        ("å¸¦å…ƒæ•°æ®çš„æ¶ˆæ¯", messages_with_metadata),
        ("å·¥å…·æ¶ˆæ¯ç±»å‹", tool_message_types),
        ("é€šç”¨èŠå¤©æ¶ˆæ¯", chat_message_types),
        ("æ¶ˆæ¯ç»„ç»‡æ–¹å¼", message_organization_examples),
        ("ç‰¹æ®Šç”¨æ³•ç¤ºä¾‹", special_usage_examples),
        ("æœ€ä½³å®è·µ", best_practices)
    ]

    for name, func in examples:
        print(f"\n{'='*60}")
        print(f"ğŸ“‹ è¿è¡Œç¤ºä¾‹: {name}")
        print('='*60)
        print()

        try:
            func()
        except KeyboardInterrupt:
            print(f"\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­äº†ç¤ºä¾‹: {name}")
            break
        except Exception as e:
            print(f"âŒ ç¤ºä¾‹ {name} æ‰§è¡Œå‡ºé”™: {e}")

        # è¯¢é—®æ˜¯å¦ç»§ç»­
        print("\n" + "="*60)
        try:
            user_input = input("æŒ‰Enterç»§ç»­ä¸‹ä¸€ä¸ªç¤ºä¾‹ï¼Œæˆ–è¾“å…¥'q'é€€å‡º: ")
            if user_input.lower() == 'q':
                break
        except (EOFError, KeyboardInterrupt):
            print("\nğŸ‘‹ ç”¨æˆ·é€€å‡ºç¨‹åº")
            break

    print("\n" + "="*60)
    print("âœ¨ æ¶ˆæ¯ç±»å‹å‚è€ƒæŒ‡å—ç»“æŸï¼")
    print("="*60)
    print()

    # æ¶ˆæ¯ç±»å‹æ€»ç»“
    print("ğŸ“š æ¶ˆæ¯ç±»å‹æ€»ç»“:")
    print()
    print("ğŸ·ï¸ æ ¸å¿ƒæ¶ˆæ¯ç±»å‹:")
    print("  â€¢ HumanMessage      - äººç±»ç”¨æˆ·æ¶ˆæ¯")
    print("  â€¢ AIMessage         - AIåŠ©æ‰‹å›å¤æ¶ˆæ¯")
    print("  â€¢ SystemMessage     - ç³»ç»ŸæŒ‡ä»¤æ¶ˆæ¯")
    print("  â€¢ ToolMessage       - å·¥å…·æ‰§è¡Œç»“æœæ¶ˆæ¯")
    print("  â€¢ ChatMessage       - é€šç”¨è§’è‰²æ¶ˆæ¯")
    print()
    print("âš™ï¸ æ¶ˆæ¯å±æ€§:")
    print("  â€¢ content           - æ¶ˆæ¯å†…å®¹(å¿…éœ€)")
    print("  â€¢ name              - æ¶ˆæ¯åç§°/æ ‡è¯†ç¬¦")
    print("  â€¢ additional_kwargs - é¢å¤–å…ƒæ•°æ®")
    print("  â€¢ response_metadata - å“åº”å…ƒæ•°æ®(AIMessage)")
    print("  â€¢ tool_calls        - å·¥å…·è°ƒç”¨ä¿¡æ¯(AIMessage)")
    print("  â€¢ tool_call_id      - å·¥å…·è°ƒç”¨ID(ToolMessage)")
    print("  â€¢ role              - æ¶ˆæ¯è§’è‰²(ChatMessage)")
    print()
    print("ğŸ¯ ä½¿ç”¨å»ºè®®:")
    print("  â€¢ æ¯æ¬¡å¯¹è¯éƒ½ä»¥SystemMessageå¼€å§‹ï¼Œå®šä¹‰AIè§’è‰²")
    print("  â€¢ ä½¿ç”¨HumanMessageè¡¨ç¤ºç”¨æˆ·è¾“å…¥")
    print("  â€¢ AIMessageç”¨äºä¿å­˜AIçš„å›å¤å†å²")
    print("  â€¢ å¯¹äºå·¥å…·è°ƒç”¨ï¼Œä½¿ç”¨ToolMessageè¿”å›ç»“æœ")
    print("  â€¢ ä¿æŒæ¶ˆæ¯ç»“æ„æ¸…æ™°ï¼Œå†…å®¹ç®€æ´")
    print("  â€¢ åˆç†ç»„ç»‡å¯¹è¯å†å²ï¼Œç»´æŒä¸Šä¸‹æ–‡è¿è´¯æ€§")
    print()
    print("ğŸ“– æ›´å¤šä¿¡æ¯:")
    print("  â€¢ LangChainæ¶ˆæ¯æ–‡æ¡£: https://python.langchain.com/docs/modules/messages/")
    print("  â€¢ æ¶ˆæ¯ç±»å‹APIå‚è€ƒ: https://api.python.langchain.com/en/latest/messages.html")

if __name__ == "__main__":
    main()