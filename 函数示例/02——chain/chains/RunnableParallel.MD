RunnableParallel æ˜¯LangChainä¸­çš„ä¸€ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œç”¨äºå¹¶è¡Œæ‰§è¡Œå¤š 
ä¸ªä»»åŠ¡ã€‚

  ï¿½ğŸ“‹åŸºæœ¬æ¦‚å¿µå¿µ

  RunnableParallel å…è®¸ä½ ï¼š
  - ï¿½ï¿½ï¿½åŒæ—¶æ‰§è¡Œå¤šä¸ªé“¾æˆ–ä»»åŠ¡åŠ¡
  - ï¿½ï¿½ï¿½å°†ç»“æœåˆå¹¶åˆ°ä¸€ä¸ªå­—å…¸ä¸­ä¸­
  - âš¡ æé«˜å¤„ç†æ•ˆç‡

  ï¿½ğŸ”æ‚¨ä»£ç ä¸­çš„ç¤ºä¾‹åˆ†ææ

  åœ¨æ‚¨çš„ç¬¬96-100è¡Œï¼š

  parallel_chain = RunnableParallel({
      "summary": summary_prompt | llm | StrOutputParser(),     
      "translation": translation_prompt | llm | StrOutputParser(),
      "sentiment": sentiment_prompt | llm | StrOutputParser()  
  })

  è®©æˆ‘è¯¦ç»†è§£æè¿™ä¸ªç»“æ„ï¼š

  RunnableParallel({
      "é”®å": "è¦æ‰§è¡Œçš„ä»»åŠ¡é“¾",
      "summary": summary_prompt | llm | StrOutputParser(),     
      "translation": translation_prompt | llm | StrOutputParser(),
      "sentiment": sentiment_prompt | llm | StrOutputParser()  
  })

  ï¿½ğŸ¯å·¥ä½œåŸç†ç†

  # è¾“å…¥æ•°æ®
  input_data = {"text": "ä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œæˆ‘å¿ƒæƒ…å¾ˆæ„‰å¿«ï¼"}

  # å¹¶è¡Œæ‰§è¡Œï¼š
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ RunnableParallel
 â”‚
  â”‚
 â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
  â”‚  â”‚   Summaryé“¾     â”‚  â”‚ Translationé“¾   â”‚  â”‚ Sentimenté“¾   
  â”‚ â”‚
  â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚
  â”‚ â”‚
  â”‚  â”‚ "æ€»ç»“ä»¥ä¸‹æ–‡æœ¬ï¼š" â”‚  â”‚ "ç¿»è¯‘æˆè‹±æ–‡ï¼š"   â”‚  â”‚ "åˆ†ææƒ…æ„Ÿï¼š"     â”‚ â”‚
  â”‚  â”‚ {text}          â”‚  â”‚ {text}          â”‚  â”‚ {text}        
  â”‚ â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
  â”‚           â†“                     â†“                     â†“    
    â”‚
  â”‚    "å¤©æ°”å¾ˆå¥½ï¼Œå¿ƒæƒ…æ„‰å¿«"      "Good weather..."     "ç§¯æ"  
      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
                      åˆå¹¶ä¸ºä¸€ä¸ªå­—å…¸:
                      {
                          "summary": "å¤©æ°”å¾ˆå¥½ï¼Œå¿ƒæƒ…æ„‰å¿«",     
                          "translation": "Good weather...",    
                          "sentiment": "ç§¯æ"
                      }

  ï¿½ğŸ“–å®Œæ•´ç¤ºä¾‹ä¾‹

  from langchain_core.runnables import RunnableParallel        
  from langchain_openai import ChatOpenAI
  from langchain_core.prompts import PromptTemplate
  from langchain_core.output_parsers import StrOutputParser    

  # 1. åˆ›å»ºLLM
  llm = ChatOpenAI(model="glm-4", temperature=0.7)

  # 2. å®šä¹‰ä¸åŒçš„æç¤ºæ¨¡æ¿
  summary_prompt = PromptTemplate(
      input_variables=["text"],
      template="æ€»ç»“ä»¥ä¸‹æ–‡æœ¬çš„è¦ç‚¹ï¼š\n{text}\n\nè¦ç‚¹ï¼š"        
  )

  translation_prompt = PromptTemplate(
      input_variables=["text"],
      template="å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼š\n{text}\n\nTranslationï¼š
"
  )

  sentiment_prompt = PromptTemplate(
      input_variables=["text"],
      template="åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼ˆç§¯æ/æ¶ˆæ/ä¸­æ€§ï¼‰ï¼š\n{text}\n\næƒ…æ„Ÿï¼š"
  )

  # 3. åˆ›å»ºå¹¶è¡Œé“¾
  parallel_chain = RunnableParallel({
      "summary": summary_prompt | llm | StrOutputParser(),     
      "translation": translation_prompt | llm | StrOutputParser(),
      "sentiment": sentiment_prompt | llm | StrOutputParser()  
  })

  # 4. æ‰§è¡Œå¹¶è¡Œä»»åŠ¡
  test_text = "ä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œæˆ‘å¿ƒæƒ…å¾ˆæ„‰å¿«ï¼"

  results = parallel_chain.invoke({"text": test_text})

  print(f"åŸå§‹æ–‡æœ¬: {test_text}")
  print("å¹¶è¡Œå¤„ç†ç»“æœ:")
  for key, value in results.items():
      print(f"  {key}: {value}")

  ï¿½ğŸš€ä½¿ç”¨åœºæ™¯æ™¯

  1. æ–‡æœ¬å¤šè§’åº¦åˆ†æ
  # åŒæ—¶è¿›è¡Œæƒ…æ„Ÿåˆ†æã€å…³é”®è¯æå–ã€æ‘˜è¦ç”Ÿæˆ
  analysis_chain = RunnableParallel({
      "sentiment": sentiment_chain,
      "keywords": keywords_chain,
      "summary": summary_chain
  })
  2. æ•°æ®è½¬æ¢
  # åŒæ—¶è¿›è¡Œæ ¼å¼è½¬æ¢ã€éªŒè¯ã€å¢å¼º
  transform_chain = RunnableParallel({
      "original": RunnablePassthrough(),
      "formatted": format_chain,
      "validated": validation_chain,
      "enhanced": enhancement_chain
  })
  3. å¤šæ¨¡å‹å¯¹æ¯”
  # ä½¿ç”¨ä¸åŒæ¨¡å‹å¤„ç†åŒä¸€è¾“å…¥
  comparison_chain = RunnableParallel({
      "gpt4": gpt4_chain,
      "claude": claude_chain,
      "llama": llama_chain
  })

  âš¡ æ€§èƒ½ä¼˜åŠ¿

  - å¹¶å‘æ‰§è¡Œï¼šå¤šä¸ªä»»åŠ¡åŒæ—¶è¿›è¡Œï¼Œè€Œä¸æ˜¯ä¸²è¡Œ
  - å‡å°‘ç­‰å¾…æ—¶é—´ï¼šæ€»æ—¶é—´å–å†³äºæœ€æ…¢çš„ä»»åŠ¡ï¼Œè€Œä¸æ˜¯æ‰€æœ‰ä»»åŠ¡æ—¶é—´ä¹‹ 
å’Œ
  - è¾“å…¥å…±äº«ï¼šåŒä¸€ä»½è¾“å…¥å¯ä»¥å…±äº«ç»™å¤šä¸ªå¤„ç†é“¾

  ï¿½ğŸ¯é«˜çº§ç”¨æ³•æ³•

  # æ¡ä»¶å¹¶è¡Œæ‰§è¡Œ
  conditional_parallel = RunnableParallel({
      "primary": main_chain,
      "fallback": RunnableBranch(
          (lambda x: x["confidence"] > 0.8, success_chain),    
          (lambda x: True, retry_chain)
      )
  })

  # å¸¦æ•°æ®ä¼ é€’çš„å¹¶è¡Œ
  parallel_with_passthrough = RunnableParallel({
      "original": RunnablePassthrough(),  # ä¿ç•™åŸå§‹è¾“å…¥       
      "processed": processing_chain,
      "metadata": metadata_chain
  })

  ç°åœ¨æ‚¨ç†è§£ RunnableParallel çš„å·¥ä½œåŸç†äº†å—ï¼Ÿå®ƒå°±åƒæ˜¯åˆ›å»ºäº†ä¸€ 
ä¸ª"ä»»åŠ¡ç®¡ç†å™¨"ï¼Œå¯ä»¥åŒæ—¶å¤„ç†å¤šä¸ªä»»åŠ¡ï¼